{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false, "jupyter": {"outputs_hidden": true, "source_hidden": true}}, "outputs": [], "source": ["# Please do not change this cell because some hidden tests might depend on it.\n", "import os\n", "\n", "# Otter grader does not handle ! commands well, so we define and use our\n", "# own function to execute shell commands.\n", "def shell(commands, warn=True):\n", "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n", "     \n", "       Prints the result to stdout and returns the exit status. \n", "       Provides a printed warning on non-zero exit status unless `warn` \n", "       flag is unset.\n", "    \"\"\"\n", "    file = os.popen(commands)\n", "    print (file.read().rstrip('\\n'))\n", "    exit_status = file.close()\n", "    if warn and exit_status != None:\n", "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n", "    return exit_status\n", "\n", "shell(\"\"\"\n", "ls requirements.txt >/dev/null 2>&1\n", "if [ ! $? = 0 ]; then\n", " rm -rf .tmp\n", " git clone https://github.com/cs236299-2020/lab3-3.git .tmp\n", " mv .tmp/tests ./\n", " mv .tmp/requirements.txt ./\n", " rm -rf .tmp\n", "fi\n", "pip install -q -r requirements.txt\n", "\"\"\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["# Initialize Otter\n", "import otter\n", "grader = otter.Notebook()"]}, {"cell_type": "raw", "metadata": {"jupyter": {"source_hidden": true}}, "source": ["%%latex\n", "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\newcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\newcommand{\\softmax}{\\operatorname{softmax}}\n", "\\newcommand{\\Prob}{\\Pr}\n", "\\newcommand{\\given}{\\,|\\,}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$$\n", "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n", "\\renewcommand{\\Prob}{\\Pr}\n", "\\renewcommand{\\given}{\\,|\\,}\n", "$$"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "YhNwlK5J_wU_"}, "source": ["# Course 236299\n", "## Lab 3-3 - Probabilistic context-free grammars"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "w9cQ2kCv_zax"}, "source": ["In previous labs, you have practiced constituency parsing using context-free grammars with the CKY parsing algorithm. In this lab you will extend this framework to a probabilistic one, probabilistic context-free grammars (PCFG)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n", "\n", "* [`math.prod`](https://docs.python.org/3/library/math.html#math.prod)\n", "* [`nltk.tree.Tree.productions`](https://www.nltk.org/api/nltk.html?highlight=production#nltk.tree.Tree.productions)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preparations"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "editable": false, "id": "d8kPmrmwB2U9"}, "outputs": [], "source": ["import copy\n", "import math\n", "import nltk\n", "import pandas as pd\n", "\n", "from collections import Counter, defaultdict\n", "from pprint import pprint"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "ieywAjIBFLbz"}, "source": ["## Syntactic ambiguity"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "KEWCQ2cvFQrw"}, "source": ["Let's start with the following grammar for arithmetic word expressions:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "d8kPmrmwB2U9"}, "outputs": [], "source": ["arithmetic_grammar = nltk.CFG.fromstring(\"\"\"\n", "    S -> NUM | NUM OP S | S OP NUM\n", "    NUM -> 'one' | 'two' | 'three' | 'four' | 'five' \n", "    NUM -> 'six' | 'seven' | 'eight' | 'nine' | 'ten' \n", "    OP -> ADD | SUB | MULT | DIV\n", "    ADD -> 'plus' | 'added' 'to'\n", "    SUB -> 'minus' \n", "    MULT -> 'times' | 'multiplied' 'by'\n", "    DIV -> 'divided' 'by'\n", "\"\"\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "JIt2BY8yGIqP"}, "source": [">   It might have been more natural to have the rules\n", ">   ```\n", ">   S -> NUM | S OP S\n", ">   ```\n", ">   but we have purposefully introduced an ambiguity into the grammar via these more restricted rules above so that we can disambiguate later by rule weightings.\n", "\n", "We can use the given CFG to parse the phrase \"two plus three times four\" and print the possible parse trees."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "SMI2sSeQLnv-"}, "outputs": [], "source": ["parser = nltk.parse.BottomUpChartParser(arithmetic_grammar)\n", "phrase = \"two plus three times four\"\n", "parses = list(parser.parse(phrase.split()))\n", "\n", "for i, tree in enumerate(parses):\n", "  print(f\"Possible parse {i+1}:\\n\")\n", "  tree.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "v0vIENitPzq9"}, "source": ["In this example, every parse tree represents an arithmetic expression. Manually calculate the value of the resulting equation for each of the parsed trees.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: parsed_equation_result\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "iEzvvFvDP77I"}, "outputs": [], "source": ["#TODO\n", "result_tree1 = ...\n", "result_tree2 = ...\n", "result_tree3 = ...\n", "result_tree4 = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"parsed_equation_result\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "Eqsvobh2Rx4Y"}, "source": ["As you can see, we got four different parse trees, yielding different numerical results. It is interesting to notice that some of the parse trees (the pairs (1, 2) and (3, 4)) have different structures but the same \"meaning\" (same denoted value), while for other trees different structures induce different meanings (for example the pair (1, 3)).\n", "\n", "The idea of different structural interpretations is called structural ambiguity. Since natural language is oftentimes ambiguous, this is a very realistic concern. One approach to deal with this issue is by defining a scoring system to score the possible parses and choosing the highest scoring tree. We will see how this can be done by taking a probabilistic approach to CFG."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "UgobxGF0WZ7V"}, "source": ["## Probabilistic context-free grammars"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "nyMNv3sYWdmA"}, "source": ["To assign probabilities to strings, we will use a probabilistic context-free grammar (PCFG), a CFG in which each rule is augmented with a probability.\n", "\n", "The PCFG definition is derived from that of the CFG, by augmenting the rules with probabilities:\n", "\n", "* $\\cal{N}$ \u2013 a set of nonterminal symbols\n", "* $\\Sigma$ \u2013 a set of terminal symbols\n", "* $\\cal{R}$ \u2013 a set of rules or productions, each of the form $A \\rightarrow \\beta\\ [p]$,\n", "where $A$ is a nonterminal, $\\beta$ is a string of terminal or nonterminal symbols,\n", "and $p$ is a number between 0 and 1 expressing $\\Prob(\\beta \\given A)$\n", "* $S$ \u2013 a designated start symbol\n", "\n", "Note that to constitute a valid probability distribution we require that $\\sum_\\beta \\Prob(\\beta \\given A) =1$, that is, the probabilities associated with all rules with the same left-hand side must sum to one.\n", "\n", "Take a look at the following PCFG based on the arithmetic grammar above:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "7MMKDQ9sXNRs"}, "outputs": [], "source": ["probabilistic_arithmetic_grammar = nltk.PCFG.fromstring(\"\"\"\n", "    S -> NUM [0.35] | NUM OP S [0.4] | S OP NUM [0.25] \n", "    OP -> ADD [0.4] | SUB [0.2] | MULT [0.3] | DIV [0.1]\n", "    NUM -> 'one' [0.1] | 'two' [0.1] | 'three' [0.1] | 'four' [0.1] | 'five' [0.1]\n", "    NUM -> 'six' [0.1] | 'seven' [0.1] | 'eight' [0.1] | 'nine' [0.1] | 'ten' [0.1]\n", "    ADD -> 'plus' [0.8] | 'added' 'to' [0.2]\n", "    SUB -> 'minus' [1.0]\n", "    MULT -> 'times' [0.9] | 'multiplied' 'by' [0.1]\n", "    DIV -> 'divided' 'by' [1.0]\n", "\"\"\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "LJ155LVeUU9y"}, "source": ["We can use the [nltk.CFG.productions()](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.CFG.productions) method to get a list of the PCFG's productions:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "5pBrhCvNUs9m"}, "outputs": [], "source": ["probabilistic_arithmetic_grammar.productions()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "Mq8J8fQxVF4Y"}, "source": ["Each of the productions in the list is an instance of the [ProbabilisticProduction](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.ProbabilisticProduction) class. Each such instance is defined by three parameters: its left hand side (`lhs`), right-hand side (`rhs`), and rule probability (`prob`). These attributes can be accessed separately:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "4TZUYEE3Vyxt"}, "outputs": [], "source": ["pprod_example = probabilistic_arithmetic_grammar.productions()[1]\n", "print(f'For the production \"{pprod_example}\":\\n' \n", "      f'left hand side of the rule is {pprod_example.lhs()}\\n'\n", "      f'right hand side of the rule is {pprod_example.rhs()}\\n'\n", "      f'probability of the rule is {pprod_example.prob()}')"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "Qx8sTaCVWIcg"}, "source": ["For non-probabilistic grammars, the class of productions is [Production](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.Production), which doesn't have a probability attribute and is only defined by its lhs and rhs attributes:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "s67fRZjFXK4u"}, "outputs": [], "source": ["print(f'PCFG production: {probabilistic_arithmetic_grammar.productions()[1]} \\n'\n", "      f'      vs.\\n'\n", "      f'CFG production:  {arithmetic_grammar.productions()[1]}') "]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "NTRVDqDjF18j"}, "source": ["## Parse tree probabilities\n", "\n", "To use a PCFG to select among parse trees, we need to be able to calculate the probability of a parse tree. The probability of a parse tree is simply the product of the probabilities of each constituent in the tree, the probability of the rule associated with the constituent.\n", "\n", "You'll use the PCFG `probabilistic_arithmetic_grammar` to calculate the probability of each of the parse trees in `parses` (the list of trees which were parsed from the sentence \"two plus three times four\"). \n", "\n", "To do that, you'll need to get all the productions used in a parse tree (using the [productions](https://www.nltk.org/api/nltk.html?highlight=production#nltk.tree.Tree.productions) method), find their probabilities, and multiply them together.\n", "\n", "First, we will create a dictionary from the PCFG, so that we can easily access the rule probabilities. Write a function which accepts a PCFG and returns a dictionary whose keys are the CFG (not PCFG) grammar rules and values are the associated probabilities. \n", "<!--\n", "BEGIN QUESTION\n", "name: pcfg_to_dict\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "wzrUO1KNuUz4"}, "outputs": [], "source": ["#TODO - returns a dictionary whose keys are `nltk.grammar.Production` objects\n", "#       and whose values are the associated probabilities\n", "def pcfg_to_dict(pcfg):\n", "  ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"pcfg_to_dict\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "1ImGQNeTHwRT"}, "source": ["We can use the function you wrote to convert `probabilistic_arithmetic_grammar` to a dictionary and inspect it to make sure it's working."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pprint(pcfg_to_dict(probabilistic_arithmetic_grammar))"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "1ImGQNeTHwRT"}, "source": ["Now for the payoff: Write a function that takes a parse tree and a PCFG and returns the probability of the parse tree according to the PCFG. The `pcfg_to_dict` function you just wrote is likely to come in handy.\n", "\n", "> Note that we are asking for the probability (not log probability), and we **don't work in log space** in this lab for simplicity, but for parse trees of longer sentences (which we'll see in the project) we might have to work in the log space to avoid underflows.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: parsed_trees_probs\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# TODO: returns the probability of the parse tree.\n", "# `tree.productions() might be useful for getting the \n", "#  productions of a parse tree\n", "def parse_probability(tree, pcfg):\n", "    ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"parsed_trees_probs\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "1ImGQNeTHwRT"}, "source": ["We'll use it to calculate and print out the probability of each parse tree."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, tree in enumerate(parses):\n", "    print(f'Probability of parsed tree {i+1} is '\n", "          f'{parse_probability(tree, probabilistic_arithmetic_grammar):1.2e}')"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "h2F-sJGitFgs"}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "---\n", "**Question:** Which of the trees is the most probable parse? Are there trees that got the same score (probability)? Do they have the same arithmetic result? Explain.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_ambiguity\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "q0LrzA8LvY0P"}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "---\n", "## Estimating rule probabilities from a corpus"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "XzNIdwjHvlrA"}, "source": ["In the previous section, you received a CFG already augmented with rule probabilities. But where do rule probabilities come from? One way to generate rule probabilites is to learn them from a training corpus. \n", "\n", "In this section you will use a toy corpus of parsed sentences to generate maximum likelihood estimates of rule probabilities by counting the number of occurrences of a rule used in the corpus."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "HCNGAEmtJkl3"}, "outputs": [], "source": ["# The raw corpus, before splitting into separate phrases\n", "corpus_raw = \"\"\"\n", "    (S (S (NUM two) (OP plus) (S (NUM six))) (OP times) (NUM one))\n", "    (S (S (NUM eight) (OP minus) (S (NUM three))) (OP plus) (NUM seven))\n", "    (S (NUM two) (OP plus) (S (S (NUM three)) (OP times) (NUM four))) \n", "    (S (S (NUM eight) (OP divided by) (S (NUM four))) (OP times) (NUM two))\n", "    (S (S (NUM five) (OP divided by) (S (NUM two))) (OP plus) (NUM one))\n", "    (S (NUM five) (OP minus) (S (NUM one) (OP times) (S (NUM four)))) \n", "    (S (S (NUM two) (OP times) (S (NUM three))) (OP plus) (NUM four))\n", "    (S (S (S (NUM ten)) (OP minus) (NUM two)) (OP times) (NUM three))\n", "\"\"\"\n", "\n", "def corpus_from_string(raw):\n", "  \"\"\"Return a corpus as a list of sentences.\n", "  \n", "  The `raw` corpus is split at newlines, trimmed of whitespace, and blank \n", "  lines eliminated.\n", "  \"\"\"\n", "  return list(filter(lambda x: x != '', \n", "                     map(lambda sent: sent.strip(),\n", "                         raw.split('\\n'))))\n", "\n", "# The processed corpus we'll use\n", "corpus = corpus_from_string(corpus_raw)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "ep4DSx_F2Za3"}, "source": ["Recall that for the rule probabilities to define a valid probability distibution, the following needs to hold:\n", "\n", "$$\\sum_\\beta p(\\beta \\given A) =1$$\n", "\n", "Thus means that that after counting rule occurrences we will need to normalize them as\n", "\n", "\\begin{align}\n", "p(\\beta \\given A) \n", "  &= \\frac{\\cnt{A \\to \\beta}}{\\sum_{\\beta'} \\cnt{A \\to \\beta'}} \\\\\n", "  &= \\frac{\\cnt{A \\to \\beta}}{\\cnt{A}}\n", "\\end{align}\n", "\n", "We will define three functions: \n", "\n", "1. `rule_counter` - accepts a list of sentences and returns a dictionary of rule counts (where the key is the production defined by the lhs and rhs and the value is the number of rule occurrences)\n", "2. `lhs_counter` - accepts a list of sentences and returns a dictionary of lhs counts (where the key is the lhs nonterminal and the value is the count of that nonterminal's occurences as a lhs)\n", "3. `rule_probs` - accepts a list of sentences and returns a dictionary of rule probabilities (where the key is the production and the value is the rule probability).\n", "\n", "Implement these functions as specified above.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: probs_from_corpus\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "iWRrTwp-wZOu"}, "outputs": [], "source": ["#TODO \n", "def rule_counter(sentence_list):\n", "  ...\n", "\n", "#TODO\n", "def lhs_counter(sentence_list):\n", "  ...\n", "\n", "#TODO\n", "def rule_probs(sentence_list):\n", "  ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"probs_from_corpus\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "sMEdd-KSg3J5"}, "source": ["Now we can use the `rules_prob` function you wrote to get the rule probabilities from our corpus:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "Q0TCm-8vgOAR"}, "outputs": [], "source": ["probs_from_corpus = rule_probs(corpus)\n", "probs_from_corpus"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "VofTcEId8Y-n"}, "source": ["Observe that the probabilities of the two rules `S -> NUM OP S` and `S -> S OP NUM` are equivalent. **Modify** the `corpus` defined above such that the rule \"S -> NUM OP S\" will get a higher probability than \"S -> S OP NUM\". Call your new version `corpus_new`. Remember that `corpus_new` should be a list of strings, not a single string (like `corpus_raw` above).\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: change_corpus\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "l__biCtUhFyD"}, "outputs": [], "source": ["corpus_new = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"change_corpus\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "h2F-sJGitFgs"}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "---\n", "**Question:** The example that we provided of an ambiguity introduced by multiple productions and disambiguated by their probabilities \u2013 the multiple rules for arithmetic expressions \u2013 is admittedly quite artificial. Can you think of other (more natural) examples, in natural language or elsewhere, where this phenomenon might occur?\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_other_examples\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- END QUESTION -->\n", "\n", "<!-- BEGIN QUESTION -->\n", "\n", "---\n", "\n", "## Lab debrief \u2013 for consensus submission only\n", "\n", "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n", "\n", "* Was the lab too long or too short?\n", "* Were the readings appropriate for the lab? \n", "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n", "* Are there additions or changes you think would make the lab better?\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_debrief\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "# End of Lab 3-3"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["---\n", "\n", "To double-check your work, the cell below will rerun all of the autograder tests."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check_all()"]}], "metadata": {"colab": {"collapsed_sections": [], "name": "lab3-3_op3.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}, "title": "CS187 Lab 3-3: Probabilistic context-free grammars"}, "nbformat": 4, "nbformat_minor": 4}