{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab1-2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"title":"CS187 Lab 1-2: Text classification and evaluation methodology"},"cells":[{"cell_type":"code","metadata":{"id":"seYz7eP0lrok","executionInfo":{"status":"ok","timestamp":1604610646955,"user_tz":-120,"elapsed":3243,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"d0950e2e-3735-4753-8c7c-1f9c6b7f6fc9","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Please do not change this cell because some hidden tests might depend on it.\n","import os\n","\n","# Otter grader does not handle ! commands well, so we define and use our\n","# own function to execute shell commands.\n","def shell(commands, warn=True):\n","    \"\"\"Executes the string `commands` as a sequence of shell commands.\n","     \n","       Prints the result to stdout and returns the exit status. \n","       Provides a printed warning on non-zero exit status unless `warn` \n","       flag is unset.\n","    \"\"\"\n","    file = os.popen(commands)\n","    print (file.read().rstrip('\\n'))\n","    exit_status = file.close()\n","    if warn and exit_status != None:\n","        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n","    return exit_status\n","\n","shell(\"\"\"\n","ls requirements.txt >/dev/null 2>&1\n","if [ ! $? = 0 ]; then\n"," rm -rf .tmp\n"," git clone https://github.com/cs236299-2020/lab1-2.git .tmp\n"," mv .tmp/tests ./\n"," mv .tmp/requirements.txt ./\n"," rm -rf .tmp\n","fi\n","pip install -q -r requirements.txt\n","\"\"\")"],"execution_count":83,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-wVTiA_Rlroz","executionInfo":{"status":"ok","timestamp":1604610646957,"user_tz":-120,"elapsed":3227,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["# Initialize Otter\n","import otter\n","grader = otter.Notebook()"],"execution_count":84,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E3MZVE4LlrpB"},"source":["# Course 236299\n","## Lab 1-2 — Text classification and evaluation methodology"]},{"cell_type":"markdown","metadata":{"id":"fnkQc_tQlrpE"},"source":["After this lab, you should be able to\n","\n","* Understand the distinction between training and test corpora, and why both are needed;\n","* Understand the role of gold labels;\n","* Implement a majority class baseline as a benchmark to compare other methods;\n","* Implement nearest neighbor classification, and understand the role of distance metrics in its operation;\n","* Compare multiple methods for acccuracy."]},{"cell_type":"markdown","metadata":{"id":"7w4JtIx0lrpG"},"source":["New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful, include\n","\n","* [`collections.Counter`](https://docs.python.org/3/library/collections.html#collections.Counter)\n","* [`collections.Counter.most_common`](https://docs.python.org/3/library/collections.html#collections.Counter.most_common)"]},{"cell_type":"markdown","metadata":{"id":"MxJ31-zYlrpI"},"source":["## Preparation – Loading packages and data"]},{"cell_type":"code","metadata":{"id":"72a74fs0lrpK","executionInfo":{"status":"ok","timestamp":1604610646958,"user_tz":-120,"elapsed":3221,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["# Please do not change these imports because some hidden tests might depend on them.\n","# You can add a cell below if you need to import anything else.\n","import collections\n","import json\n","import math\n","import numpy as np\n","from pprint import pprint\n","import re"],"execution_count":85,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nzvEoZjxlrpU"},"source":["## The Federalist Papers\n","\n","<img src=\"https://github.com/nlp-236299/data/raw/master/Federalist/federalist.jpg\" width=150 align=right />\n","\n","The _Federalist_ papers is a collection of 85 essays written pseudonymously by Alexander Hamilton, John Jay, and James Madison following the Constitutional Convention of 1787, promoting the ratification of the nascent United States Constitution.\n","\n","The authorship of many of the individual papers has been well established and acknowledged by the various authors, but a number of the papers have been contentious, with both Madison and Hamilton as possible authors. Determining the authorship of these disputed papers is a classic text classification problem, and one that has received great attention. The seminal work on the problem is that of [Mosteller and Wallace](http://www.historyofinformation.com/detail.php?entryid=4799), who applied then-novel statistical methods to the problem. In this lab, we'll use the _Federalist_ data to experiment with some of the ideas about distance metrics and classification methods that you've read about.\n","\n","Mosteller and Wallace used the frequencies of various words in the papers as the raw data for determining authorship. We've provided access to a heavily pre-digested version of this data. (If you're interested, you can find the raw data – all 85 papers – and the notebook used to generate the pre-digested data in the [course `data` github repository](https://github.com/nlp-236299/data).)\n","\n","Start by evaluating the cells below to load the data and view a sample."]},{"cell_type":"code","metadata":{"id":"GMDQAm1SlrpY","executionInfo":{"status":"ok","timestamp":1604610646959,"user_tz":-120,"elapsed":3213,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"d518fa5c-191d-4913-e0ed-40581950398e","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Read the Federalist data from the json file\n","shell('wget -nv -N -P data https://github.com/nlp-236299/data/raw/master/Federalist/federalist_data.json')"],"execution_count":86,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sP7iYFiblrpi","executionInfo":{"status":"ok","timestamp":1604610646961,"user_tz":-120,"elapsed":3206,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["with open('data/federalist_data.json', 'r') as fin:\n","    dataset = json.load(fin)"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"id":"IkdAIvv2lrpr","executionInfo":{"status":"ok","timestamp":1604610646965,"user_tz":-120,"elapsed":3201,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"b092c241-9eb2-48d7-85c6-9d9e3a854002","colab":{"base_uri":"https://localhost:8080/"}},"source":["# View a sample of the data\n","print(f\"Number of papers in the dataset: {len(dataset)}\")\n","print(\"Some examples:\")\n","pprint(dataset[:3])"],"execution_count":88,"outputs":[{"output_type":"stream","text":["Number of papers in the dataset: 85\n","Some examples:\n","[{'authors': 'Hamilton',\n","  'counts': [9, 6, 2, 0],\n","  'number': '1',\n","  'title': 'General Introduction'},\n"," {'authors': 'Jay',\n","  'counts': [8, 1, 0, 0],\n","  'number': '2',\n","  'title': 'Concerning Dangers from Foreign Force and Influence'},\n"," {'authors': 'Jay',\n","  'counts': [6, 0, 1, 0],\n","  'number': '3',\n","  'title': 'The Same Subject Continued: Concerning Dangers from Foreign Force '\n","           'and Influence'}]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d4EgaYznlrp2"},"source":["You'll see above that the dataset is a list of _examples_, one for each paper, each a dictionary providing the paper number, its title and author(s), and the raw counts for a few important words in the papers. (From the last lab, you'll recognize the `counts` field as a bag-of-words representation of the document.) The `counts` field is the document representation that we will be wanting to classify, and the `authors` field contains the pertinent class label for each example. \n","\n","For your reference, here are the words that were used to derive the counts:"]},{"cell_type":"code","metadata":{"id":"UBQPaJ2Zlrp4","executionInfo":{"status":"ok","timestamp":1604610646968,"user_tz":-120,"elapsed":3193,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["keywords = ['on', 'upon', 'there', 'whilst']"],"execution_count":89,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eid2HMdxlrqF"},"source":["Thus in the first example paper, _Federalist 1_, there were 9 tokens of \"on\", 6 of \"upon\", 2 of \"there\", and none of \"whilst\". \n","\n","The `authors` field takes on various values. Here's a table of the frequency of each of the values. (This will come in handy later.)"]},{"cell_type":"code","metadata":{"id":"ZafPq4sQlrqH","executionInfo":{"status":"ok","timestamp":1604610646970,"user_tz":-120,"elapsed":3186,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"88efcde0-0bf9-4bbe-8602-4b177f13713a","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Generate a table of the number of papers by each author label\n","cnt = collections.Counter(map(lambda ex: ex['authors'],\n","                              dataset))\n","for author, count in cnt.items():\n","    print(f\"{count:3d} ({count/len(dataset):.3f}%) {author}\")"],"execution_count":90,"outputs":[{"output_type":"stream","text":[" 51 (0.600%) Hamilton\n","  5 (0.059%) Jay\n"," 15 (0.176%) Madison\n","  3 (0.035%) Hamilton and Madison\n"," 11 (0.129%) Hamilton or Madison\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tv5ef3AjlrqU"},"source":["As you can see, some of the papers are of known authorship by Madison or Hamilton. We can use these as training data."]},{"cell_type":"code","metadata":{"id":"i04dw2jXlrqV","executionInfo":{"status":"ok","timestamp":1604610646971,"user_tz":-120,"elapsed":3178,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["# Extract the papers by either of Madison and Hamilton\n","training = list(filter(lambda ex: ex['authors'] in ['Madison', 'Hamilton'],\n","                       dataset))"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"It10OYU4lrqd","executionInfo":{"status":"ok","timestamp":1604610646973,"user_tz":-120,"elapsed":3172,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"6c07dc49-a929-4619-a4ac-d31e5d6f9314","colab":{"base_uri":"https://localhost:8080/"}},"source":["# View a sample of the training data\n","print(f\"Number of papers in the dataset: {len(training)}\")\n","print(\"Some examples:\")\n","pprint(training[:3])"],"execution_count":92,"outputs":[{"output_type":"stream","text":["Number of papers in the dataset: 66\n","Some examples:\n","[{'authors': 'Hamilton',\n","  'counts': [9, 6, 2, 0],\n","  'number': '1',\n","  'title': 'General Introduction'},\n"," {'authors': 'Hamilton',\n","  'counts': [2, 4, 7, 0],\n","  'number': '6',\n","  'title': 'Concerning Dangers from Dissensions Between the States'},\n"," {'authors': 'Hamilton',\n","  'counts': [13, 11, 9, 0],\n","  'number': '7',\n","  'title': 'The Same Subject Continued: Concerning Dangers from Dissensions '\n","           'Between the States'}]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"70c8BDrclrqk"},"source":["Others of the papers are of ambiguous authorship. They are shown as having `'Hamilton or Madison'` as author. These will be the elements that we want to test our models on."]},{"cell_type":"code","metadata":{"id":"Gz-IcJUNlrql","executionInfo":{"status":"ok","timestamp":1604610647381,"user_tz":-120,"elapsed":3571,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["# Extract the papers of unknown authorship\n","testing = list(filter(lambda ex: ex['authors'] == 'Hamilton or Madison',\n","                      dataset))"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaYVJPG0lrqt","executionInfo":{"status":"ok","timestamp":1604610647384,"user_tz":-120,"elapsed":3565,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"233f9cca-a146-4224-a1cd-d2d0e4117e3b","colab":{"base_uri":"https://localhost:8080/"}},"source":["# View a sample of the data\n","print(f\"Number of papers in the dataset: {len(testing)}\")\n","print(\"Some sample elements:\")\n","pprint(testing[:3])"],"execution_count":94,"outputs":[{"output_type":"stream","text":["Number of papers in the dataset: 11\n","Some sample elements:\n","[{'authors': 'Hamilton or Madison',\n","  'counts': [16, 0, 2, 1],\n","  'number': '49',\n","  'title': 'Method of Guarding Against the Encroachments of Any One Department '\n","           'of Government by Appealing to the People Through a Convention'},\n"," {'authors': 'Hamilton or Madison',\n","  'counts': [11, 1, 0, 0],\n","  'number': '50',\n","  'title': 'Periodic Appeals to the People Considered'},\n"," {'authors': 'Hamilton or Madison',\n","  'counts': [21, 0, 2, 2],\n","  'number': '51',\n","  'title': 'The Structure of the Government Must Furnish the Proper Checks and '\n","           'Balances Between the Different Departments'}]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j-rMPxIzlrq-"},"source":["## Models for text classification"]},{"cell_type":"markdown","metadata":{"id":"D_pxluHplrrA"},"source":["We can think of a _model_ for a text classification problem as a function taking a test example and returning a class label for the test example. Generating the model will rely on a corpus of training data.\n","\n","With a model in hand, we can evaluate its _accuracy_ on a test corpus by computing the proportion of test examples that the model correctly classifies. Define a higher-order function `accuracy` that takes a test corpus (like `testing`) and a model (which is a function, remember), and returns the accuracy of the model on that corpus. \n","\n","<!--\n","BEGIN QUESTION\n","name: accuracy\n","-->"]},{"cell_type":"code","metadata":{"id":"L-YQGsjRlrrB","executionInfo":{"status":"ok","timestamp":1604610647386,"user_tz":-120,"elapsed":3559,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["# TODO\n","def accuracy(test_corpus, model):\n","    correct = len([ex for ex in test_corpus if model(ex) == ex['authors']])\n","    return correct / len(test_corpus)\n","    "],"execution_count":95,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mZ0Ras83lrra"},"source":["### Majority class classification\n","\n","An especially simple classification model labels each test example with whichever label happens to occur most frequently in the training data. It completely ignores the test example that it classifies!\n","\n","By examination of the table provided above, what is the majority class label for this dataset?\n","\n","<!--\n","BEGIN QUESTION\n","name: maj_class_label\n","-->"]},{"cell_type":"code","metadata":{"id":"ba5Qmz72lrrb","executionInfo":{"status":"ok","timestamp":1604610647390,"user_tz":-120,"elapsed":3556,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["maj_class_label = 'Hamilton' if cnt['Hamilton'] > cnt['Madison'] else 'Madison'\n"],"execution_count":96,"outputs":[]},{"cell_type":"code","metadata":{"id":"k689dXcmlrrm","executionInfo":{"status":"ok","timestamp":1604610647394,"user_tz":-120,"elapsed":3546,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"8dfb89b8-7e1b-4319-bc19-366cae93bca7","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"maj_class_label\")"],"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"markdown","metadata":{"id":"2lOEbOf5lrru"},"source":["Define a function `majority_class_label` that returns the majority class label for a training set.\n","<!--\n","BEGIN QUESTION\n","name: majority_class_label\n","-->"]},{"cell_type":"code","metadata":{"id":"prjBYbjFlrrw","executionInfo":{"status":"ok","timestamp":1604610647397,"user_tz":-120,"elapsed":3536,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO\n","def majority_class_label(training):\n","  labels = [ex['authors'] for ex in training]\n","  label =  max(labels, key = labels.count)\n","  return label"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"id":"20Wvha5mlrsB","executionInfo":{"status":"ok","timestamp":1604610647400,"user_tz":-120,"elapsed":3522,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"60504265-89bc-4096-ddcf-0d5ee0edfa5f","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"majority_class_label\")"],"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"markdown","metadata":{"id":"zfA70sXXlrsZ"},"source":["What proportions of the **training** examples would be classified correctly by the majority class model?\n","<!--\n","BEGIN QUESTION\n","name: maj_class_accuracy_guess\n","-->"]},{"cell_type":"code","metadata":{"id":"9JfTTCGElrsc","executionInfo":{"status":"ok","timestamp":1604610647402,"user_tz":-120,"elapsed":3510,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO\n","maj_class_accuracy_guess = cnt['Hamilton'] / (cnt['Hamilton'] + cnt['Madison'])"],"execution_count":100,"outputs":[]},{"cell_type":"code","metadata":{"id":"uU46iNI2lrsl","executionInfo":{"status":"ok","timestamp":1604610647404,"user_tz":-120,"elapsed":3493,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"fa303c94-50aa-49b8-b32a-1b69d854d9f6","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"maj_class_accuracy_guess\")"],"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":101}]},{"cell_type":"markdown","metadata":{"id":"dxtAi_3Tlrss"},"source":["Now define a function `majority_class` that takes a single argument, a test example, and returns the class label that is most frequent in the training data `training` (regardless of what the test example is).\n","<!--\n","BEGIN QUESTION\n","name: majority_class\n","-->"]},{"cell_type":"code","metadata":{"id":"CfKLUJHBlrss","executionInfo":{"status":"ok","timestamp":1604610647405,"user_tz":-120,"elapsed":3483,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO - define the `majority_class` model\n","def majority_class(example):\n","    return majority_class_label(training)"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"id":"3f_QXrpwlrsy","executionInfo":{"status":"ok","timestamp":1604610647407,"user_tz":-120,"elapsed":3469,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"2d248719-5034-4bae-a09d-6fec9c775f4c","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"majority_class\")"],"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"markdown","metadata":{"id":"-iXtDa0Ulrs4"},"source":["Now we can see how well this majority class model works by trying it out on some examples. Use the `accuracy` function to determine the model's accuracy when applied to the task of labeling the _training_ data?\n","<!--\n","BEGIN QUESTION\n","name: accuracy_maj_class_train\n","-->"]},{"cell_type":"code","metadata":{"id":"zlcRfnYqlrs5","executionInfo":{"status":"ok","timestamp":1604610647409,"user_tz":-120,"elapsed":3461,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO - define `maj_class_on_train` to be the accuracy of the majority class model on the training data\n","accuracy_maj_class_train = accuracy(training, majority_class)"],"execution_count":104,"outputs":[]},{"cell_type":"code","metadata":{"id":"Akm2ifqslrtA","executionInfo":{"status":"ok","timestamp":1604610647411,"user_tz":-120,"elapsed":3449,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"99dad428-01a5-4e2a-d21c-f840208e2701","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"accuracy_maj_class_train\")"],"execution_count":105,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"code","metadata":{"id":"CBCiJp-tlrtH","executionInfo":{"status":"ok","timestamp":1604610647412,"user_tz":-120,"elapsed":3436,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"43292f80-c90a-43e2-9d0e-f99179b5eb64","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(f\"Accuracy of the majority class model on training data: {accuracy_maj_class_train:.3f}\")"],"execution_count":106,"outputs":[{"output_type":"stream","text":["Accuracy of the majority class model on training data: 0.773\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ztYCPMb6lrtN"},"source":["Was your estimation from above right?"]},{"cell_type":"markdown","metadata":{"id":"qIfyKAJwlrtP"},"source":["### Nearest neighbor classification\n","\n","Recall that nearest neighbor classification classifies a test example with the label of the nearest training example. To calculate nearest neighbors, we need a distance metric between the representations of the documents. Below we've provided two such metrics, familiar from the previous lab, for Euclidean distance and cosine distance."]},{"cell_type":"code","metadata":{"id":"cAyZSr6OlrtR","executionInfo":{"status":"ok","timestamp":1604610647414,"user_tz":-120,"elapsed":3429,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["def euclidean_distance(v1, v2):\n","    '''Returns the Euclidean distance between two vectors''' \n","    return np.linalg.norm(np.array(v1) - np.array(v2))"],"execution_count":107,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqMceHYJlrtW","executionInfo":{"status":"ok","timestamp":1604610647415,"user_tz":-120,"elapsed":3424,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["def safe_acos(x):\n","    '''Returns the arc cosine of `x`. Unlike `math.acos`, it \n","       does not raise an exception for values of `x` out of range, \n","       but rather clips `x` at -1..1, thereby avoiding math domain\n","       errors in the case of numerical errors.'''\n","    return math.acos(math.copysign(min(1.0, abs(x)), x))\n","        \n","def cosine_distance(v1, v2):\n","    '''Returns the cosine distance between two vectors'''\n","    return (safe_acos(np.dot(v1, v2) \n","                      / (np.linalg.norm(v1, 2) * np.linalg.norm(v2, 2)))\n","            / math.pi)"],"execution_count":108,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"go0jjM98lrtc"},"source":["#### Generating nearest neighbor models"]},{"cell_type":"markdown","metadata":{"id":"BEpIs818lrtd"},"source":["To specify a nearest neighbor model, we need both a training corpus (like `training`) and a distance metric (like `euclidean_distance` or `cosine_distance` defined just above). \n","\n","Define a function called `define_nearest_neighbor` that takes a training corpus and a metric and returns a model - that is, a **function** that classifies a single test example. The model should return the class label of that training example whose counts vector is closest to that of the test example according to the metric.\n","\n","<!--\n","BEGIN QUESTION\n","name: define_nearest_neighbor\n","-->"]},{"cell_type":"code","metadata":{"id":"JNqcooU7lrte","executionInfo":{"status":"ok","timestamp":1604610647417,"user_tz":-120,"elapsed":3419,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["    def define_nearest_neighbor(corpus, metric):\n","        model = lambda x: min([(paper, metric(x['counts'], paper['counts']))\n","                            for paper in corpus], key=lambda t: t[1]\n","                            )[0]['authors']\n","        return model"],"execution_count":109,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SuhoeZyXlrtn"},"source":["We can use the `define_nearest_neighbor` function to define two new models for nearest neighbor classification, one using Euclidean distance and one using cosine distance."]},{"cell_type":"code","metadata":{"id":"0bz-bsy0lrtn","executionInfo":{"status":"ok","timestamp":1604610647419,"user_tz":-120,"elapsed":3415,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["nearest_neighbor_euclidean_model = \\\n","    define_nearest_neighbor(training, euclidean_distance)\n","\n","nearest_neighbor_cosine_model = \\\n","    define_nearest_neighbor(training, cosine_distance)"],"execution_count":110,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8O7o-xB3lrtr"},"source":["#### Testing the nearest neighbor models on the training data"]},{"cell_type":"markdown","metadata":{"id":"yNpO4Ki7lrtt"},"source":["How accurate are these models when used to label the training data (as we did for the majority class model above)? Use the `accuracy` function above to calculate the accuracy of `nearest_neighbor_euclidean_model` in labeling the _training_ data (not the test data), and similarly for `nearest_neighbor_cosine_model`.\n","<!--\n","BEGIN QUESTION\n","name: accuracy_train\n","-->"]},{"cell_type":"code","metadata":{"id":"UvBMAGoOlrtt","executionInfo":{"status":"ok","timestamp":1604610647421,"user_tz":-120,"elapsed":3410,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO - define the variable to be the calculated accuracy \n","accuracy_nn_euclidean_train = accuracy(training, nearest_neighbor_euclidean_model)\n","accuracy_nn_cosine_train = accuracy(training, nearest_neighbor_cosine_model)"],"execution_count":111,"outputs":[]},{"cell_type":"code","metadata":{"id":"jRsDX3dMlrtx","executionInfo":{"status":"ok","timestamp":1604610647423,"user_tz":-120,"elapsed":3398,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"3c1ae1a6-c396-46cf-d828-72b5eb25704c","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"accuracy_train\")"],"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"id":"CVMvek18lrt1","executionInfo":{"status":"ok","timestamp":1604610647843,"user_tz":-120,"elapsed":3807,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"61990fb8-f888-45ac-f2da-223c0a23f63f","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(f\"Accuracy of the nearest neighbor euclidean model tested on training data: \"\n","      f\"{accuracy_nn_euclidean_train:.3f}\")\n","print(f\"Accuracy of the nearest neighbor cosine model tested on training data: \"\n","      f\"{accuracy_nn_cosine_train:.3f}\")"],"execution_count":113,"outputs":[{"output_type":"stream","text":["Accuracy of the nearest neighbor euclidean model tested on training data: 1.000\n","Accuracy of the nearest neighbor cosine model tested on training data: 1.000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rV_R3vfHlrt4"},"source":["<!-- BEGIN QUESTION -->\n","\n","**Question:** Does the performance of these classifiers on the training data seem to you to be representative of how good a classifier each is? Why or why not?\n","<!--\n","BEGIN QUESTION\n","name: open_response_1\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"iQRijy5llrt4"},"source":["No, because in both metrics we use the training dataset, all of samples we've allready learned, i.e memorized, thus we find the exact sample, which is the most close to itself (0.0 distance) and predict exactly it's label. To measure the performance, it is desirable to use examples which weren't seen  by the model.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lbLRUVrflrt5"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","#### Testing the nearest neighbor models on the testing data"]},{"cell_type":"markdown","metadata":{"id":"FCzyRTBwlrt5"},"source":["To get a better sense of how the nearest neighbor models perform, let's try them out on the testing data that we have. (Recall that the testing data in `testing` were the ambiguously-authored Federalist papers, where the `authors` field was `'Hamilton or Madison'`.)\n","\n","We start by looking in detail at the predictions generated by the two nearest neighbor models. Print out a table that lists, for each `testing` example, the paper number and the authors predicted under the nearest neighbor Euclidean model and the nearest neighbor cosine model.\n","<!--\n","BEGIN QUESTION\n","name: print_table\n","-->"]},{"cell_type":"code","metadata":{"id":"ZK5My6P8lrt6","executionInfo":{"status":"ok","timestamp":1604610647845,"user_tz":-120,"elapsed":3798,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"9cb45854-3d17-49b6-eb89-7d68398a3508","colab":{"base_uri":"https://localhost:8080/"}},"source":["# TODO\n","table_euclidean = [(ex['number'], nearest_neighbor_euclidean_model(ex)) for ex in testing]\n","print('Euclidean:')\n","print(table_euclidean)\n","\n","table_cosine = [(ex['number'], nearest_neighbor_cosine_model(ex)) for ex in testing]\n","\n","print('Cosine:')\n","print(table_cosine)"],"execution_count":114,"outputs":[{"output_type":"stream","text":["Euclidean:\n","[('49', 'Madison'), ('50', 'Hamilton'), ('51', 'Madison'), ('52', 'Madison'), ('53', 'Madison'), ('54', 'Madison'), ('55', 'Madison'), ('56', 'Madison'), ('57', 'Madison'), ('62', 'Madison'), ('63', 'Madison')]\n","Cosine:\n","[('49', 'Madison'), ('50', 'Madison'), ('51', 'Madison'), ('52', 'Madison'), ('53', 'Madison'), ('54', 'Madison'), ('55', 'Hamilton'), ('56', 'Madison'), ('57', 'Madison'), ('62', 'Madison'), ('63', 'Madison')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v5HHhLYblrt_"},"source":["<!-- BEGIN QUESTION -->\n","\n","What do you notice about the two models?\n","<!--\n","BEGIN QUESTION\n","name: open_response_2\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"pFl_g_-tlruA"},"source":["Both model use nearest neighbour algorithm and  differ only by the metric to calculate the distance between neighbours of the given example. Both agree on most of the test examples predictions, in which 'Madison' is predicted to be the author, but differ in one test example prediction, what is generally a coincidence (they could differ on any number of predictions)."]},{"cell_type":"markdown","metadata":{"id":"ptJxy3xBlruA"},"source":["<!-- END QUESTION -->\n","\n","#### Accuracy on the testing corpus\n","\n","Now use the `accuracy` function to calculate the accuracy of the two nearest neighbor models as you did above, but this time calculating accuracy on the testing corpus rather than the training corpus. (Expect to find a surprising result. Read ahead for an explanation if you're confused.)\n","<!--\n","BEGIN QUESTION\n","name: accuracy_test\n","-->"]},{"cell_type":"code","metadata":{"id":"yz0wjTiLlruB","executionInfo":{"status":"ok","timestamp":1604610647849,"user_tz":-120,"elapsed":3790,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO - define the variables to be the calculated accuracy of the nearest \n","# neighbor Euclidean model and the cosine model on the testing data\n","\n","accuracy_nn_euclidean_test = accuracy(testing, nearest_neighbor_euclidean_model)\n","accuracy_nn_cosine_test = accuracy(testing, nearest_neighbor_cosine_model)\n"],"execution_count":115,"outputs":[]},{"cell_type":"code","metadata":{"id":"my9xX_6jlruE","executionInfo":{"status":"ok","timestamp":1604610647851,"user_tz":-120,"elapsed":3781,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"63a64b27-d9ad-4397-b501-176e958dbbd6","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"accuracy_test\")"],"execution_count":116,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":116}]},{"cell_type":"code","metadata":{"id":"g9akr23elruO","executionInfo":{"status":"ok","timestamp":1604610647853,"user_tz":-120,"elapsed":3770,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"53a06263-aaf4-4f53-c936-0bb047164314","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(f\"Accuracy of the nearest neighbor euclidean model tested on training data: \"\n","      f\"{accuracy_nn_euclidean_test:.3f}\")\n","print(f\"Accuracy of the nearest neighbor cosine model tested on training data: \"\n","      f\"{accuracy_nn_cosine_test:.3f}\")"],"execution_count":117,"outputs":[{"output_type":"stream","text":["Accuracy of the nearest neighbor euclidean model tested on training data: 0.000\n","Accuracy of the nearest neighbor cosine model tested on training data: 0.000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FRujbrBjlruS"},"source":["<!-- BEGIN QUESTION -->\n","\n","**Question:** Does the performance of these classifiers on the testing data seem to you to be representative of how good a classifier each is? Why or why not?\n","<!--\n","BEGIN QUESTION\n","name: open_response_3\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"eK11-ilXlruT"},"source":["It isn't representative, because the groundtruth labels are unknown. In our case the test set composed of papers, authors of which addressed as \"Hamilton or Madison\", and our prediction by each model is \"Hamilton\" or \"Madison\", thus the accuracy function, which eventually calculates the number of true result comparisons of the predicted authors and the groundtruth, just get 0 because niether \"Madison\" nor \"Hamilton\" equals to \"Hamilton or Madison\", so the accuracy is 0. For overcoming this issue, it is desiarble to have some groundtruth labels for the testing (as in generally in classification problems), for example those can be in out case the gold labels (labels that were produced by humans, as described in the reading material)."]},{"cell_type":"markdown","metadata":{"id":"WOyuCX30lruU"},"source":["<!-- END QUESTION -->\n","\n","#### The importance of gold labels\n","\n","In order to evaluate the accuracy of the nearest neighbor model – and any model – we need to have the true labels for the testing corpus, the so-called _gold_ labels. What shall we use for gold labels? Mosteller and Wallace's much more extensive analysis concluded that all of the papers of ambiguous origin were penned by Madison, so we'll use that. We should modify the `testing` corpus to inject the gold labels. \n","\n","Write some code to update the testing corpus with the gold labels.\n","<!--\n","BEGIN QUESTION\n","name: get_gold\n","-->"]},{"cell_type":"code","metadata":{"id":"Vf1j601GlruV","executionInfo":{"status":"ok","timestamp":1604610647855,"user_tz":-120,"elapsed":3761,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO - write code to update the testing corpus with the gold labels\n","for ex in testing:\n","    if ex['authors'] == 'Hamilton or Madison':\n","        ex['authors'] = 'Madison'\n","\n"],"execution_count":118,"outputs":[]},{"cell_type":"code","metadata":{"id":"5jU1j4kVlruZ","executionInfo":{"status":"ok","timestamp":1604610647859,"user_tz":-120,"elapsed":3749,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"b07cabca-14a6-4bf6-e654-ec8e32bb5f77","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"get_gold\")"],"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":119}]},{"cell_type":"markdown","metadata":{"id":"-FxX1P9llruj"},"source":["Now we can rerun the accuracy calculations."]},{"cell_type":"code","metadata":{"id":"wSD_MkBMlruk","executionInfo":{"status":"ok","timestamp":1604610647861,"user_tz":-120,"elapsed":3743,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["accuracy_nn_euclidean_test_with_gold = accuracy(testing, nearest_neighbor_euclidean_model)\n","accuracy_nn_cosine_test_with_gold = accuracy(testing, nearest_neighbor_cosine_model)"],"execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwkRmj1blrur","executionInfo":{"status":"ok","timestamp":1604610647863,"user_tz":-120,"elapsed":3736,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"3e6d518e-b8cf-4969-d73d-5e5c8f9de916","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(f\"Accuracy of the nearest neighbor euclidean model tested on testing data: \"\n","      f\"{accuracy_nn_euclidean_test_with_gold:.3f}\")\n","print(f\"Accuracy of the nearest neighbor cosine model tested on testing data: \"\n","      f\"{accuracy_nn_cosine_test_with_gold:.3f}\")"],"execution_count":121,"outputs":[{"output_type":"stream","text":["Accuracy of the nearest neighbor euclidean model tested on testing data: 0.909\n","Accuracy of the nearest neighbor cosine model tested on testing data: 0.909\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZamlVdaBlruz"},"source":["Do these results make more sense?"]},{"cell_type":"markdown","metadata":{"id":"dziPuCRMlru0"},"source":["<!-- BEGIN QUESTION -->\n","\n","## Lab debrief – for consensus submission only\n","\n","**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n","\n","* Was the lab too long or too short?\n","* Were the readings appropriate for the lab? \n","* Was it clear (at least after you completed the lab) what the points of the exercises were? \n","* Are there additions or changes you think would make the lab better?\n","\n","<!--\n","BEGIN QUESTION\n","name: open_response_debrief\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"LR4F9cs_lru1"},"source":["_Type your answer here, replacing this text._"]},{"cell_type":"markdown","metadata":{"id":"LOL37tuWlru1"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","# End of lab 1-2"]},{"cell_type":"markdown","metadata":{"id":"fXMk3pJBlru2"},"source":["---\n","\n","To double-check your work, the cell below will rerun all of the autograder tests."]},{"cell_type":"code","metadata":{"id":"L5lLKNLrlru3","executionInfo":{"status":"ok","timestamp":1604610647865,"user_tz":-120,"elapsed":3728,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"e8d05b99-c9af-4c89-b334-8b5bdde0fbdf","colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["grader.check_all()"],"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/html":["<p><strong>accuracy_maj_class_train:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>accuracy_test:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>accuracy_train:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>get_gold:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>maj_class_accuracy_guess:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>maj_class_label:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>majority_class:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>majority_class_label:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n"],"text/plain":["accuracy_maj_class_train:\n","\n","    All tests passed!\n","    \n","\n","accuracy_test:\n","\n","    All tests passed!\n","    \n","\n","accuracy_train:\n","\n","    All tests passed!\n","    \n","\n","get_gold:\n","\n","    All tests passed!\n","    \n","\n","maj_class_accuracy_guess:\n","\n","    All tests passed!\n","    \n","\n","maj_class_label:\n","\n","    All tests passed!\n","    \n","\n","majority_class:\n","\n","    All tests passed!\n","    \n","\n","majority_class_label:\n","\n","    All tests passed!\n","    \n"]},"metadata":{"tags":[]},"execution_count":122}]}]}