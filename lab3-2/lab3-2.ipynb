{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false, "jupyter": {"outputs_hidden": true, "source_hidden": true}}, "outputs": [], "source": ["# Please do not change this cell because some hidden tests might depend on it.\n", "import os\n", "\n", "# Otter grader does not handle ! commands well, so we define and use our\n", "# own function to execute shell commands.\n", "def shell(commands, warn=True):\n", "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n", "     \n", "       Prints the result to stdout and returns the exit status. \n", "       Provides a printed warning on non-zero exit status unless `warn` \n", "       flag is unset.\n", "    \"\"\"\n", "    file = os.popen(commands)\n", "    print (file.read().rstrip('\\n'))\n", "    exit_status = file.close()\n", "    if warn and exit_status != None:\n", "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n", "    return exit_status\n", "\n", "shell(\"\"\"\n", "ls requirements.txt >/dev/null 2>&1\n", "if [ ! $? = 0 ]; then\n", " rm -rf .tmp\n", " git clone https://github.com/cs236299-2020/lab3-2.git .tmp\n", " mv .tmp/tests ./\n", " mv .tmp/requirements.txt ./\n", " rm -rf .tmp\n", "fi\n", "pip install -q -r requirements.txt\n", "\"\"\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["# Initialize Otter\n", "import otter\n", "grader = otter.Notebook()"]}, {"cell_type": "raw", "metadata": {}, "source": ["%%latex\n", "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\newcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\newcommand{\\softmax}{\\operatorname{softmax}}\n", "\\newcommand{\\Prob}{\\Pr}\n", "\\newcommand{\\given}{\\,|\\,}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$$\n", "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n", "\\renewcommand{\\Prob}{\\Pr}\n", "\\renewcommand{\\given}{\\,|\\,}\n", "$$"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "VDT_jXJT19x9"}, "source": ["# Course 236299\n", "## Lab 3-2 \u2013 Context-free parsing\n", "\n", "In this lab, you'll carry out a simple context-free recognition and parsing algorithm, the CKY algorithm independently discovered by John Cocke, Tadao Kasami, and Daniel Younger.\n", "\n", "By carrying out and understanding this lab, you should be able to\n", "\n", "* Distinguish recognition from parsing,\n", "* Understand the string position representation of constituents, and\n", "* Follow recognition algorithms for context-free grammars."]}, {"cell_type": "markdown", "metadata": {}, "source": ["New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n", "\n", "* [pandas.DataFrame.iloc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html#pandas-dataframe-iloc)\n", "* [set.add](https://docs.python.org/3/library/stdtypes.html#frozenset.add)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "WhjodbQx2FQk"}, "source": ["## Preparation \u2013 Loading packages"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 51}, "colab_type": "code", "deletable": false, "editable": false, "id": "Zd5YUDQ52Ikz", "outputId": "bce24983-d546-463d-cdc1-05ae1eb5bf35"}, "outputs": [], "source": ["from collections import defaultdict\n", "import functools\n", "import numpy as np\n", "import nltk\n", "import pandas as pd"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "k4enV7BQnbbA"}, "source": ["## CKY Recognition\n", "In the previous lab, you worked with context-free grammars (CFGs), and practiced defining grammars and parse trees.\n", "\n", "This lab will focus on the Cocke-Kasami-Younger (CKY) parsing algorithm.\n", "The input to the algorithm is a grammar in Chomsky Normal Form (CNF) and a sentence; the output of the algorithm is the set of parse trees that yield the given sentence according to the grammar (or the empty set if there are no such parse trees).\n", "\n", "We will first focus on the CKY _recognition_ algorithm, that only outputs whether the given sentence can be parsed or not. Then, we will see how to slightly modify this algorithm (by adding back-pointers) to also generate the parse trees themselves."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "NW0x7hqvVmgC"}, "source": ["## The sample grammar\n", "\n", "Recall the simple arithmetic grammar that you wrote in the previous lab. In this lab, you'll use a simplified version, containing fewer operators and numbers."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["arithmetic_grammar = nltk.CFG.fromstring( \n", "    \"\"\"\n", "    S -> NUM | S OP S\n", "    OP -> ADD | SUB | MULT | DIV\n", "\n", "    NUM -> 'zero' | 'one' | 'two' | 'three' \n", "    \n", "    ADD -> 'plus'\n", "    SUB -> 'minus' \n", "    MULT -> 'times'\n", "    \"\"\" \n", ")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "NW0x7hqvVmgC"}, "source": ["The CKY algorithm requires grammars in Chomsky Normal Form. Here is a CNF-converted version of the grammar, which makes use of an additional nonterminal `SOP`, which derives prefixes of `S` missing an `S` at the right edge, strings like, for instance, `one plus` or `one plus two times`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 255}, "colab_type": "code", "id": "zDZbjNG82i-C", "outputId": "3a5a3785-3ae4-40bb-d074-4dc6bc998fcc"}, "outputs": [], "source": ["cnf_arithmetic_grammar = nltk.CFG.fromstring(\n", "    \"\"\"\n", "    S -> 'zero' | 'one' | 'two' | 'three'\n", "    S -> SOP S \n", "    \n", "    SOP -> S ADD | S SUB | S MULT\n", "\n", "    ADD -> 'plus'\n", "    SUB -> 'minus' \n", "    MULT -> 'times'\n", "    \"\"\"\n", ")\n", "\n", "print(cnf_arithmetic_grammar)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "XkwQuwnhWaSq"}, "source": ["We can verify that the grammar is in CNF, as required by the CKY algorithm."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 34}, "colab_type": "code", "id": "rbR5S13ZnIgZ", "outputId": "82361fe2-483b-49e6-8925-4e1c3da87ec7"}, "outputs": [], "source": ["cnf_arithmetic_grammar.is_chomsky_normal_form()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "4a0XePr3Wqvv"}, "source": ["Given the sentence \"*one plus two times three*\", what would be its parse tree according to the grammar?\n", "\n", "Without any specific handling of arithmetic operator precedence, this \"sentence\" can be either parsed as:\n", "\n", "* `(one plus two) times three`\n", "\n", "or:\n", "\n", "* `one plus (two times three)`"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "qdhqLAgiYTWS"}, "source": ["Let's see how a parser parses this sentence:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 391}, "colab_type": "code", "id": "XEihL7hE3Ran", "outputId": "402cad61-8ca2-48a0-9a13-8ec8126d4305"}, "outputs": [], "source": ["sentence = \"one plus two times three\"\n", "words = sentence.split()\n", "\n", "parser = nltk.parse.BottomUpChartParser(cnf_arithmetic_grammar)\n", "for tree in parser.parse(words):\n", "    tree.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "fpcp_Nhwbg_A"}, "source": ["As you can see, `nltk`'s parser finds the two possible parses. In this lab, you will manually parse this sentence using the CKY algorithm.\n", "\n", "The CKY algorithm is a simple dynamic programming algorithm. Dynamic programming algorithms work by solving every subproblem of a given problem, in an order such that larger subproblems can merely recombine solutions of smaller subproblems already solved. In the case of CNF parsing, the subproblems are the parsing of _every substring_ as _every nonterminal_. In the end, of course, all we care about is whether the _entire string_ can be parsed as _the start nonterminal_. But by calculating all of the subproblems in order from the shortest to the longest substrings, we can acquire the information we need in the end.\n", "\n", "<img src=\"https://github.com/nlp-course/data/raw/master/Resources/cky-chart.png\" width=400 align=right />\n", "\n", "We start by representing the string to be parsed in such a way that we can represent each of its substrings compactly. Consider the string `one plus two times three`. We can think of the positions between the words as being numbered from zero to the length of the string (5), as depicted in the figure at right. Then any substring can be characterized by the string position to its left and the string position to its right, which we'll call a _span_. For instance, the substring `one plus` corresponds to the span 0\u20132 and `two times three` to the span 2\u20135. Adjacent spans (like these two) share a string position, in this case the string position 2, which corresponds to the \"split point\" that divides the spans. Two adjacent spans can be combined to form a longer one; the full span is between the left string position of the left span and the right string position of the right span, 0\u20135.\n", "\n", "Some substrings are generated by the grammar from particular nonterminals. For instance, in the example at right, the substring in the span 0\u20132 is generated by the grammar as an `SOP`, and 2\u20135 as an `S`. We'll call a span generable by a particular nonterminal a _potential constituent_.\n", "\n", "The CKY algorithm proceeds by generating every potential subconstituent of the string to be parsed. It does so by filling in a table `T` indexed by two string positions (a span, specifying a substring) whose entries are sets of nonterminals that can generate the substring between the string positions. Thus, the algorithm in parsing the string `one plus two times three` will place `SOP` in the table at entry `T[0, 2]` and `S` at entry `T[2, 5]`. It follows from these two entries, plus the existence of a rule `S -> SOP S` in the grammar, that there should also be an entry `S` in `T[0, 5]`. By filling in these table entries in a particular order, making use of entries previously filled out, the full set of potential subconstiuents can be determined, and hence, the particular question of whether `S` covers the entire string can be answered simply by inspecting `T[0, N]`.\n", "\n", "Here is the CKY algorithm in pseudo-code:\n", "\n", "```\n", " 1.  define cky-parse(string = w1, ..., wN, grammar):\n", " 2.      for j in [1..N]:                     # each end string position\n", "\n", "             # handle rules of the form A -> w\n", "             # where wj is the \"current\" word\n", " 3.          for all A where A --> wj in grammar:\n", " 4.              add A to T[j-1, j]\n", "\n", "             # handle rules of the form A -> B C\n", " 5.          for length in [2..j]:            # each subconstituent length\n", " 6.              i := j - length              # start string position\n", " 7.              for split in [i+1..j-1]      # each split point\n", " 8.                  for all A where \n", " 9.                          A -> B C in grammar\n", "10.                          and B in T[i, split]\n", "11.                          and C in T[split, j]:\n", "12.                      add A to T[i, j]\n", "13.      if S in T[0, N]:\n", "             return \"parsed\"\n", "         else:\n", "             return \"failed\"\n", "```\n", "\n", "The idea is that we parse the sentence bottom-up, where in every step we check whether a given subsequence of the input can be derived from any single nonterminal. If we perform this in the right order (as above), at every step we already know whether each of the possible splits of the subsequence creates valid subparses.\n", "\n", "In this lab, you'll carry out the CKY algorithm manually. *We recommend keeping the above algorithm open in another window so you can use it throughout the lab without scrolling*.\n", "\n", "> A detail concerning implementing the algorithm in Python, with its zero-based indexing: Zero-based indexing works quite naturally for the table `T`, since the string positions start with zero. However, the input sentence itself uses one-based indexing, that is, the first word in the input sentence is denoted as `w1` in the pseudo-code. To make it easier to follow the algorithm, we can match our indices to the algorithm's by adding a dummy symbol at the start of the sentence."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 34}, "colab_type": "code", "id": "JXUdqS-PRX0K", "outputId": "cc58df0e-c055-42d7-b698-e35f41249f5a"}, "outputs": [], "source": ["words = [''] + sentence.split()\n", "words"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "XkZcUJweRAa5"}, "source": ["For the table, we'll use a `pandas` dataframe, primarily for its readable output. (We don't recommend using this data structure when implementing the CKY algorithm variants in project segment 3.)\n", "\n", "* Entries that contain `'---'` do not need to be modified.\n", "* To denote entries that contain no non-terminals, we will use `set()` as their content (an empty set).\n", "* To denote entries that contain one or more nonterminals `A`, `B`, and `C`, we will use, e.g., `set(['A'])` or `set(['A','B','C'])`"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "TgOwHTT1aMPY", "outputId": "0aeb5135-0a77-40b5-93ed-a270331e11c2"}, "outputs": [], "source": ["data = [\n", "        ['---',  set(),  set(),  set(),  set(),  set()],\n", "        ['---',  '---',  set(),  set(),  set(),  set()],\n", "        ['---',  '---',  '---',  set(),  set(),  set()],\n", "        ['---',  '---',  '---',  '---',  set(),  set()],\n", "        ['---',  '---',  '---',  '---',  '---',  set()],\n", "        ['---',  '---',  '---',  '---',  '---',  '---'],\n", "]\n", "\n", "table = pd.DataFrame(data, columns=words, index=list('012345'))\n", "table.columns = pd.MultiIndex.from_arrays([table.columns] + [list('012345')])\n", "table"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "cqMXBAZujxn7"}, "source": ["We will now manually track the execution of the algorithm. The first step in the algorithm is a loop for `j` starting at `1`. Then, \n", "\n", "```\n", " 3.          for all A where A --> wj in grammar:\n", " 4.              add A to T[j-1, j]\n", "```\n", "\n", "In the case at hand `wj` (that is `w1`, that is `words[1]`) is `one`. And sure enough there is a rule in the grammar of the required form, namely, `S -> 'one'`. So we must update the table accordingly.\n", "\n", "In the next cell, update the relevant entry in the table.\n", "\n", "> You can use the `pandas` method `table.iloc[row, col]` for indexing and the `set` method `add` to add a nonterminal to a set.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: table_addition_1\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "AvdBHKHojTAS", "outputId": "43c70b63-603d-4a2d-cf2e-1e15351d38e2"}, "outputs": [], "source": ["#TODO -- update the table for the first step of j=1\n", "# 3.          for all A where A --> wj in grammar:\n", "# 4.              add A to T[j-1, j]\n", "..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"table_addition_1\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's examine the table to make sure it worked."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "AvdBHKHojTAS", "outputId": "43c70b63-603d-4a2d-cf2e-1e15351d38e2"}, "outputs": [], "source": ["table"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "fHWBxXVtpPYi"}, "source": ["Now the next line in the algorithm specifies a loop for all lengths from 2 to `j`. But `j` is `1`, so the loop is vacuous.\n", "\n", "> Why lengths starting at 2? Because for shorter strings, there's no way to split the string into two non-empty parts. And in CNF grammars, there are no empty constituents.\n", "\n", "We're back to lines 3-4 with `j` now having the value 2. Update the table accordingly in the next cell.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: table_addition_2\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "kWjIMD3iSUyH", "outputId": "8ddc2e84-7755-4410-b800-d0ca46b46762"}, "outputs": [], "source": ["#TODO -- update the table\n", "..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"table_addition_2\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "kWjIMD3iSUyH", "outputId": "8ddc2e84-7755-4410-b800-d0ca46b46762"}, "outputs": [], "source": ["table"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "V_ABtf53SgwQ"}, "source": ["Again, we're at line 5, selecting a length from the range [2..2]. There's only one such length, 2, so the start string position `i` is `j-2`, that is `0`. For strings between string positions 0 and 2, there is only one possible split point, namely 1. At line 7, then, there will thus be only a single iteration.\n", "\n", "Lines 8-12 have us find all rules in the grammar of the form $A \\rightarrow B\\, C$ such that `B` is in `T[i, split]` and `C` is in `T[split, j]`, and add such `A` values to the table. \n", "\n", "Update the table accordingly in the next cell.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: table_addition_3\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "iWhx0H5bUKyd", "outputId": "e78273cd-6d39-4447-b5af-c846c2519272"}, "outputs": [], "source": ["#TODO -- update the table\n", "..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"table_addition_3\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "iWhx0H5bUKyd", "outputId": "e78273cd-6d39-4447-b5af-c846c2519272"}, "outputs": [], "source": ["table"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "J7lrILOpUaXu"}, "source": ["Both loops that iterate over $i$ and over $split$ had a single iteration, so we can continue with $j=3$.\n", "\n", "Complete the table according to the algorithm, starting from $j=3$. Remember, it is okay that a given entry will not have any nonterminals. In that case, the entry value will remain the empty set.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: table_addition_rest\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "NtL7xxIkU57s", "outputId": "f9d41193-c498-40f8-f8a1-e910ba8cce81"}, "outputs": [], "source": ["#TODO \u2013 update the table\n", "..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"table_addition_rest\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "NtL7xxIkU57s", "outputId": "f9d41193-c498-40f8-f8a1-e910ba8cce81"}, "outputs": [], "source": ["table"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "qZEIpiwKaq8G"}, "source": ["The entry that represents the entire input resides at position `[0,5]`. Since our sentence should be parsable by the grammar as the start symbol `S`, the following expression should hold if the string is generated by the grammar."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 34}, "colab_type": "code", "id": "VrA73PRja6DI", "outputId": "6775f963-366c-481b-92d6-d2b332ac389d"}, "outputs": [], "source": ["'S' in table.iloc[0,5]"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "N5sYBf2Ddka1"}, "source": ["# CKY Parsing\n", "The algorithm that we executed so far is a _recognizer_, not a parser \u2013 if the algorithm ends with a non-empty entry in `table[0,n]` \u2013 it means that the input is parsable, but it doesn't directly provide information about the input's parse trees.\n", "\n", "However, we want to know not only _whether_ the string is parsable, but _how_. We'd like the parse trees themselves. The necessary modification to the algorithm is to keep in the table entries not only a nonterminal that covers the substring, but the `split` value and production that was used as well.\n", "\n", "We will define another table called `back` to keep that information. A `back` table value will be a mapping from nonterminals into a set of values for `split` and the right-hand side of the rule that was used. We use a set because there may be several such split and production values. We initialize the entries to a dictionary mapping to empty sets."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "9xawqymrOa2-", "outputId": "225d5c4b-9cf1-4fce-c670-aee5d824ab34"}, "outputs": [], "source": ["def empty():\n", "    return defaultdict(set)\n", "\n", "back_data = [\n", "        ['---',  empty(),  empty(),  empty(),  empty(),  empty()],\n", "        ['---',  '---',    empty(),  empty(),  empty(),  empty()],\n", "        ['---',  '---',    '---',    empty(),  empty(),  empty()],\n", "        ['---',  '---',    '---',    '---',    empty(),  empty()],\n", "        ['---',  '---',    '---',    '---',    '---',    empty()],\n", "        ['---',  '---',    '---',    '---',    '---',    '---'],\n", "]\n", "\n", "back = pd.DataFrame(back_data, columns=words, index=list('012345'))\n", "back.columns = pd.MultiIndex.from_arrays([back.columns] + [list('012345')])\n", "back"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "ttduz8DxP_Z5"}, "source": ["Recall (lines 8-12) that we update the `table` every time we find a rule $A\\longrightarrow BC$ and `split` such that\n", "\n", "```\n", " 9.                          A -> B C in grammar\n", "10.                          and B in T[i, split]\n", "11.                          and C in T[split, j]:\n", "```\n", "\n", "In addition to updating `table`, we can also then add to `back` information about `split` and the rule `A -> B C`. We augment the algorithm with a new line 12.5 like this:\n", "\n", "```\n", "12.                      add A to T[i, j]\n", "12.5.                    add <split, B, C> to back[i, j, A]\n", "```\n", "\n", "For example, for `i = 0`, `split = 1`, and `j = 2` and the found rule `SOP -> S ADD`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "gMhRNv4QegCI", "outputId": "889c0778-3111-4cc7-a74a-4d55c34ebbff"}, "outputs": [], "source": ["back.iloc[0,2]['SOP'].add((1,'S','ADD'))\n", "back"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "t6qpBNnefS6U"}, "source": ["Copy the statements in which you assigned a non-empty value into `table[i,j]` into the code cell below, starting from `j=3`. Then, instead of only assigning a non-terminal into `table[i,j]`, also fill the corresponding value of `back[i,j]`. \n", "\n", "(You can either re-run the assignments into `table[i,j]`, or comment them and run only the assignments into `back[i,j]`.)\n", "\n", "The dictionary in the final entry, `back[0,5]`, should map `S` onto a set with two elements because there are two possible ways to parse the input.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: table_addition_rest_back\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "ssliHsnsfVJl", "outputId": "6f780417-26bb-4d04-b2d6-7b616329156a"}, "outputs": [], "source": ["#TODO -- update the back table\n", "..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"table_addition_rest_back\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 266}, "colab_type": "code", "id": "ssliHsnsfVJl", "outputId": "6f780417-26bb-4d04-b2d6-7b616329156a"}, "outputs": [], "source": ["back"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "O6hftmIMlJDd"}, "source": ["Now, instead of only telling whether the input sentence is parsable or not, we can also construct the parse trees!\n", "\n", "The idea is as follows: we start from `back[0, 5]` with the entry for `S`. For each value in the set in that entry, we construct a parse tree whose root is `S`.\n", "\n", "Suppose that `back[0, 5]` contains: `{'S': {(k1, A1, B1), (k2, A2, B2)}}`. We'll reconstruct parse trees for each of the two options. Start with `(k1, A1, B1)`. We recursively construct all possible parse trees based on the `A1` nonterminal covering `[0, k1]` and all possible parse trees based on `B1` covering `[k1, 5]`. Then for each of the `A1` and `B1` trees, we construct a tree (using parentheses notation) of the form `(S (A1 ...) (B1 ...))`. We do the same for the other option `(k2, A2, B2)`. In this way, we'll generate all parse trees for the string.\n", "\n", "As it turns out, for the particular string we've been using, there is only one parse tree generable by each of the two options, so there are only two parse trees for the sentence.\n", "\n", "Start from `back[0, 5]`, and construct the two possible parse trees by using this method. Enter the two parses as `tree1` and `tree2` in the cell below.\n", "\n", "> Note that as a convention we don't put quotation marks around terminals when we use `nltk.Tree.fromstring`. For example, if the tree has root `S` and two terminals `one` and `two`, then we construct the parse using `tree = nltk.Tree.fromstring(\"(S one two)\")` **instead of** `tree = nltk.Tree.fromstring(\"(S 'one' 'two')\")`.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: parse_trees\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 391}, "colab_type": "code", "id": "uATX9wlfdUjJ", "outputId": "1471058a-d21a-42a1-f2b9-c21e2042be7c"}, "outputs": [], "source": ["#TODO -- complete the strings using bracket-notation\n", "tree1 = nltk.Tree.fromstring(\n", "    ...\n", ") \n", "tree2 = nltk.Tree.fromstring(\n", "    ...\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"parse_trees\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's check your parse trees. Are they the same as the parse trees returned by the NLTK parser?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tree1.pretty_print()\n", "tree2.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "## Lab debrief \u2013 for consensus submission only\n", "\n", "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n", "\n", "* Was the lab too long or too short?\n", "* Were the readings appropriate for the lab? \n", "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n", "* Are there additions or changes you think would make the lab better?\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_debrief\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "# End of lab 3-2"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["---\n", "\n", "To double-check your work, the cell below will rerun all of the autograder tests."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check_all()"]}], "metadata": {"colab": {"collapsed_sections": ["VDT_jXJT19x9"], "name": "lab3-2.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}, "title": "CS187 Lab 3-2: Context-free parsing"}, "nbformat": 4, "nbformat_minor": 4}