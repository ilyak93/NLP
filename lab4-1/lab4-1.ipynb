{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false, "jupyter": {"outputs_hidden": true, "source_hidden": true}}, "outputs": [], "source": ["# Please do not change this cell because some hidden tests might depend on it.\n", "import os\n", "\n", "# Otter grader does not handle ! commands well, so we define and use our\n", "# own function to execute shell commands.\n", "def shell(commands, warn=True):\n", "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n", "     \n", "       Prints the result to stdout and returns the exit status. \n", "       Provides a printed warning on non-zero exit status unless `warn` \n", "       flag is unset.\n", "    \"\"\"\n", "    file = os.popen(commands)\n", "    print (file.read().rstrip('\\n'))\n", "    exit_status = file.close()\n", "    if warn and exit_status != None:\n", "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n", "    return exit_status\n", "\n", "shell(\"\"\"\n", "ls requirements.txt >/dev/null 2>&1\n", "if [ ! $? = 0 ]; then\n", " rm -rf .tmp\n", " git clone https://github.com/cs236299-2020/lab4-1.git .tmp\n", " mv .tmp/tests ./\n", " mv .tmp/requirements.txt ./\n", " rm -rf .tmp\n", "fi\n", "pip install -q -r requirements.txt\n", "\"\"\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["# Initialize Otter\n", "import otter\n", "grader = otter.Notebook()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Lab 4-1 - First-order logic, lambda calculus, semantic parsing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preparation - Loading packages"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Download code for augmented grammars\n", "shell(\"\"\"\n", "  wget -nv -N -P scripts https://raw.githubusercontent.com/nlp-course/data/master/scripts/trees/transform.py\n", "\"\"\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["import sys\n", "import pprint\n", "\n", "import nltk\n", "\n", "# Import functions for transforming augmented grammars\n", "sys.path.insert(1, './scripts')\n", "import transform as xform"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## First-order logic\n", "\n", "In this lab, we'll use first-order logic (FOL), augmented by the lambda calculus of functions, as the formal representation of meaning for a language in the air travel domain.\n", "\n", "Recall that FOL formulas are composed of constants, variables, predicates over them, logical operators over the predicates, and quantifiers. \n", "\n", "A first-order model describes what the constants denote, and what values the predicates are true of. For example, a model of the flight world, might consist of the following:\n", "\n", "* **Constants**:\n", "    * (places) Boston, New York, Tel Aviv\n", "    * (times) Morning, Evening\n", "    * (flights) DL10, DL11, DL13, LY01, LY12\n", "    \n", "* **Predicates**: \n", "    * *Flight*: DL10, DL11, DL13, LY01, LY12\n", "    * *Origin*:  (DL10, Boston), (DL11, Boston), (DL13, New York), (LY01, Tel Aviv), (LY12, New York) \n", "    * *Destination*:  (DL10, New York), (DL11, Tel Aviv), (DL13, Boston), (LY01, New York), (LY12, Tel Aviv) \n", "    * *DepartureTime*:  (DL10, Morning), (DL11, Evening), (DL13, Evening), (LY01, Evening), (LY12, Morning) \n", "    * *ArrivalTime*:  (DL10, Morning), (DL11, Morning), (DL13, Evening), (LY12, Evening) "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using this model, we can express propositions such as \"DL13 is a flight\" and \"DL13 departs in the evening\" with formulas of FOL: \n", "* Flight(DL13)\n", "* DepartureTime(DL13, Evening)\n", "\n", "We can also combine expressions using Boolean operators to express statements like \"DL13 departs from Boston in the evening\":\n", "* DepartureTime(DL13, Evening) $\\land$ Origin(DL13, Boston)"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["We use variables to refer to objects that are not specified. Variables are quantified to either express the existence of an object or to refer to all objects:\n", "\n", "\\begin{align*}\n", "1. \\ \\ &\\exists x. Flight(x) \\land Origin(x, Boston)  \\\\\n", "2. \\ \\ &\\forall x. Flight(x) \\implies Origin(x, Boston) \n", "\\end{align*}\n", "\n", "Write a plain English description (natural language, informal description) of the meaning (a \"gloss\") for each of these expressions:\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: gloss_samples\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# TODO -- Provide an English gloss in the form of a string for each formula\n", "gloss1 = ...\n", "gloss2 = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"gloss_samples\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Determine the truth values of the above propositions under the model of the flight world given above: \n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: truth_samples\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# TODO -- Fill in the truth values for the two propositions as Python booleans\n", "statement1 = ...\n", "statement2 = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"truth_samples\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Implementing a model of the flight world\n", "We will need a Python implementation of the flight world. Our constants will be string objects:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Constants\n", "Boston = \"Boston\"\n", "NewYork = \"New York\"\n", "TelAviv = \"Tel Aviv\"\n", "\n", "DL10 = \"DL10\"\n", "DL13 = \"DL13\"\n", "LY01 = \"LY01\"\n", "LY12 = \"LY12\"\n", "DL11 = \"DL11\"\n", "\n", "Morning = \"Morning\"\n", "Evening = \"Evening\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Our predicates will be sets of objects or tuples. We have defined some of the predicates below. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Predicates\n", "Object = {Boston, NewYork, TelAviv, DL10, DL11, DL13, LY01, LY12, Morning, Evening}\n", "Flight = {DL10, DL11, DL13, LY01, LY12}\n", "Origin = {(DL10, Boston), (DL11, Boston), (DL13, NewYork), (LY01, TelAviv), (LY12, NewYork)}\n", "Destination = { (DL10, NewYork), (DL11, TelAviv), (DL13, Boston), (LY01, NewYork), (LY12, TelAviv) }"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Complete the definition of the predicates by defining `DepartureTime` and `ArrivalTime` according to the flight world given above. Assume that the first element of the tuple is the flight object and the second element is the time. \n", "\n", "Reminder:\n", "*  \n", "    * *DepartureTime*:  (DL10, Morning), (DL11, Evening), (DL13, Evening), (LY01, Evening), (LY12, Morning) \n", "    * *ArrivalTime*:  (DL10, Morning), (DL11, Morning), (DL13, Evening), (LY12, Evening) \n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: finish_world\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# TODO\n", "DepartureTime = ...\n", "ArrivalTime = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"finish_world\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Given this implementation, we can determine truth values of simple FOL propositions. To check whether DL10 has an origin of Boston, that is, that the proposition $Origin(DL10, Boston)$ is true, we use set membership:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(DL10, Boston) in Origin"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Next, test whether DL10 has an origin of Boston and a destination of New York:\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: dl10_endpoints\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# TODO -- Construct a Python expression that tests the proposition\n", "result = ...\n", "print(result)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"dl10_endpoints\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["## Lambda calculus\n", "The lambda calculus is a simple notation for functions. By embedding FOL in the lambda calculus, it allows us to build functions over propositions of various sorts, and build up propositions from component parts by applying those functions.\n", "\n", "For example, $\\lambda x\\ldotp Origin(x,Boston)$ is a function from entities to truth values, true just in case the entity is a thing (presumably a flight, though that isn't checked) whose origin is Boston. This expression thus defines a _property_, the property of originating in Boston.\n", "\n", "These lambda functions can be applied to arguments. Applying the expression above to $DL1$, gives us the expression $(\\lambda x\\ldotp Origin(x,Boston)) (DL10)$. This can be simplified through the normal lambda calculus rules ([$\\beta$-reduction](https://en.wikipedia.org/wiki/Lambda_calculus#\u03b2-reduction)) to $Origin(DL10, Boston)$, expressing the proposition that flight DL10 has Boston as its origin. (As it turns out, that proposition is false. Nothing stops us from expressing falsities.)\n", "\n", "You may recognize the similarity between this $\\lambda$ notation, due to [Alonzo Church, inventor of the lambda calculus](https://en.wikipedia.org/wiki/Alonzo_Church), and [Python's syntax for defining anonymous functions](https://docs.python.org/3/reference/expressions.html#lambda), such as `lambda x: (x, Boston) in Origin`. (This is not a coincidence, even though [Guido van Rossum is not a fan](https://www.artima.com/weblogs/viewpost.jsp?thread=98196).) The happy fact that Python already embeds a proper implementation of the lambda calculus means that we do not have to implement the lambda calculus ourselves. We'll just use Python `lambda`.\n", "\n", "Given our implementation of the flight world, define Python `lambda` functions corresponding to the following glosses:\n", "\n", "1. Something that has a destination of New York\n", "1. Flights from Tel Aviv arriving in the evening\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: simple_lambda\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# TODO\n", "expr1 = ...\n", "expr2 = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"simple_lambda\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["You can apply your functions on objects from the world and verify that you get the expected result. Use the expressions you just defined to check whether (1) flight DL10 has a destination of New York; and (2) whether flight LY01 is an evening-arriving flight from Tel Aviv. \n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: simple_lambda_2\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# TODO\n", "result1 = ...\n", "result2 = ...\n", "print(result1)\n", "print(result2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"simple_lambda_2\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "---\n", "**Question:** Notice that our flight world is underspecified, since flight LY01 does not have an arrival time. Is the result you got in `result2` desired? Would you suggest a different result? \n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_1\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "---\n", "## Semantic parsing\n", "Semantic parsing (or analysis) is the task of converting a natural language sentence to a semantic representation, such as first-order logic. We will use a syntax-driven approach to semantic parsing, where context-free grammar rules are augmented with semantic augmentations, providing meanings for constituents derived by each rule. The meaning of each expression will be a function of the meaning of the expression's subconstituents. The meanings and the ways to combine them are defined in a syntactic-semantic grammar. For example, given a syntactic rule $A \\rightarrow B\\, C$, the meaning of $A$ is a function of the meaning of $B$ and the meaning of $C$. \n", "\n", "We want to be able to convert syntactic trees of natural language queries to FOL representations of the meanings of the associated queries. For example, given a sentence \"flights from Boston to New York\", we want to obtain the FOL expression $Flight(x) \\land Origin(x, Boston) \\land Destination(x, New York)$. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### An example grammar of flights\n", "\n", "Let us define a simple syntactic grammar for natural language queries about flights in our flight world. The grammar should cover sentences such as the following:\n", "* \"flights from Boston to New York\"\n", "* \"flights from Tel Aviv departing in the morning\" \n", "\n", "> In working with this grammar here and below, do not change the order of the productions in the grammar, as our unit tests depend on the order."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grammar, _ = xform.parse_augmented_grammar(\"\"\"\n", "    NP -> 'flights'\n", "    NP -> NP PP\n", "    \n", "    PP -> PP_PLACE\n", "    PP -> PP_TIME\n", "    \n", "    PP_PLACE -> 'from' LOC \n", "              | 'leaving' LOC\n", "              | 'to' LOC\n", "              | 'arriving' 'at' LOC\n", "\n", "    PP_TIME -> 'arriving' TIME \n", "             | 'departing' TIME\n", "             | 'leaving' TIME\n", "\n", "    LOC -> 'Boston'\n", "    LOC -> 'New' 'York' \n", "    LOC -> 'Tel' 'Aviv'\n", "\n", "    TIME -> 'in' 'the' 'morning' \n", "    TIME -> 'in' 'the' 'evening'\n", "\"\"\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(grammar)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["There are several things to notice about this grammar.\n", "\n", "1. We use the `parse_augmented_grammar` function provided by `scripts.transform` (which we downloaded during the setup), to provide a more pleasant format for specifying grammars and augmented grammars. This format allow for blank lines and comment lines, separating alternatives on separate lines, and (although we haven't used it yet) adding semantic augmentations to the syntactic rules.\n", "\n", "1. The grammar mixes familiar nonterminals like parts of speech and phrases (NP for noun phrases, PP for prepositional phrase) with nonterminals of a more semantic flavor, like LOC for location or TIME for time. But, the grammar is syntactic in the sense that it operates on sentences and provides their structure. \n", "\n", "1. The function returns two values, a grammar in standard NLTK format, and a dictionary storing the augmentations, about which more later."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Augmenting the grammar with semantic composition functions\n", "\n", "Next, we will augment this grammar with rule meanings to construct logical expressions. For each production in the grammar, we'll provide a function that takes as arguments the meanings of the subconstituents (one for each nonterminal on the right-hand side of the production) and returns the meaning of the full constituent. For those rules that have no right-hand side nonterminals, their meaning will thus be a function that takes no arguments (in Python, written as `lambda: ...`).\n", "\n", "Before going further, make sure you fully understand this idea. The idea behind compositional semantics systems like this is that the meaning of a constituent is determined by (is a function of) the meanings of its subconstituents. We'll call these functions _composition functions_. In our implementation, we are taking this _literally_, by having the function of the subconstituent meaning be an _actual Python function_. Some perhaps surprising things follow:\n", "\n", "1. Since the meanings might themselves be functions, these composition functions may themselves return functions.\n", "2. Since the subconstituent meanings might themselves be functions, these composition functions may take functions as arguments.\n", "3. Since there may be zero subconstiuents of a constiuent, these composition functions may take no arguments.\n", "\n", "For instance, trees admitted by the syntactic production `NP -> 'flights'` have no (nontrivial) subconstituents. The production might have a composition function `lambda: lambda x: x in Flight`. Similarly, the production `TIME -> 'in' 'the' 'morning'` might have a semantic composition function `lambda: Morning`.\n", "\n", "We add augmentations to the grammar by placing them on the same line as the syntactic rule they augment, after a colon (`:`). Here we've added a few augmentations."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grammar_spec_1 = \"\"\"\n", "    NP -> 'flights'                 : lambda: lambda x: x in Flight\n", "    NP -> NP PP\n", "    \n", "    PP -> PP_PLACE\n", "    PP -> PP_TIME\n", "    \n", "    PP_PLACE -> 'from' LOC \n", "              | 'leaving' LOC\n", "              | 'to' LOC\n", "              | 'arriving' 'at' LOC\n", "\n", "    PP_TIME -> 'arriving' TIME \n", "             | 'departing' TIME\n", "             | 'leaving' TIME\n", "\n", "    LOC -> 'Boston'\n", "    LOC -> 'New' 'York'\n", "    LOC -> 'Tel' 'Aviv'\n", "\n", "    TIME -> 'in' 'the' 'morning'    : lambda: Morning\n", "    TIME -> 'in' 'the' 'evening'    : lambda: Evening\n", "\"\"\"\n", "\n", "grammar_1, augmentations_1 = xform.parse_augmented_grammar(grammar_spec_1)"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Now it's your turn to add augmentations for the other productions **that have no nonterminals on the right-hand side** (just those for now).\n", "<!--\n", "BEGIN QUESTION\n", "name: q_grammar_spec_2\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## TODO - copy grammar_spec_1 from above and add augmentations \n", "#         for productions with no nonterminals on the right-hand side\n", "# Note: do not change the order of productions!\n", "grammar_spec_2 = ...\n", "\n", "grammar_2, augmentations_2 = xform.parse_augmented_grammar(grammar_spec_2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"q_grammar_spec_2\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["What about the rule `PP_TIME -> 'arriving' TIME`? A phrase like \"arriving in the morning\" ought to be associated with a Python expression that is true of things that arrive in the morning, that is, `lambda x: (x, Morning) in ArrivalTime`. We can work backwards from there. \n", "\n", "We know that the composition function for the rule will be a function of one argument, the meaning of the `TIME` subconstituent \"in the morning\", which we've already determined to be `Morning`.\n", "\n", "(Ask yourself, why isn't it `lambda: Morning`? Make sure you understand why before moving on.)\n", "\n", "Thus, the augmentation will be of the form `lambda Time: ...`, which will end up being applied to `Morning`, so that `Time` in this particular case will end up being `Morning`. What should you fill in for the `...` so that the result of the application will be `lambda x: (x, Morning) in ArrivalTime`?\n", "\n", "Add an augmentation for the `PP_TIME -> 'arriving' TIME` rule to the grammar based on your solution.\n", "<!--\n", "BEGIN QUESTION\n", "name: q_grammar_spec_3\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## TODO - copy grammar_spec_2 from above and add augmentations \n", "#         for production PP_TIME -> 'arriving' TIME\n", "# Note: do not change the order of productions!\n", "grammar_spec_3 = ...\n", "grammar_3, augmentations_3 = xform.parse_augmented_grammar(grammar_spec_3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"q_grammar_spec_3\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Once you get that augmentation in place, many others should be straightforward. Fill in augmentations for all of the PP_PLACE and PP_TIME productions.\n", "\n", "And what about the productions `PP -> PP_PLACE` and `PP -> PP_TIME`? Their composition functions are simple, since the meaning of the `PP` is just the same as the meaning of its right-hand side element. What compostition function can achieve that? Fill in the augmentations for those rules too.\n", "\n", "Finally, the trickiest case is the composition function for the `NP -> NP PP` rule. Since it has two nonterminals on the right-hand side, it should be a function of two arguments, that is, something like `lambda NP, PP: ...`. This function will be applied to the meanings of the two subconstituents. The meanings for its two subconstituents, the NP and the PP, are each themselves going to be a function specifying a kind of property (like \"being a flight\" (`lambda x: x in Flight`) or \"originating in New York\" (`lambda x: (x, NewYork) in Origin`)). For the full constituent, its meaning should also be a property, namely the conjunction of the NP- and PP-provided properties (\"being a flight and originating in New York\" (`lambda x: x in Flight and (x, NewYork) in Origin`)). Define an appropriate augmentation that can do that as well, and add it to the grammar to complete the semantic augmentations.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: q_grammar_spec_4\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## TODO - copy grammar_spec_3 from above and add augmentations \n", "#         for productions PP_PLACE -> *, PP_TIME -> *, \n", "#         PP -> PP_PLACE, PP -> PP_TIME, and NP -> NP PP\n", "# Note: do not change the order of productions!\n", "grammar_spec_4 = ...\n", "grammar_4, augmentations_4 = xform.parse_augmented_grammar(grammar_spec_4)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"q_grammar_spec_4\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The `parse_augmented_grammar` function we've provided returns two values, an NLTK grammar based on the syntactic productions, and a dictionary that maps those productions onto the corresponding semantic augmentations. We can examine them individually."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(grammar_4)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pprint.pprint(augmentations_4)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The semantic functions aren't much to look at. Python doesn't print out very useful information about them. But you can test them to see if they do the right thing. For instance, the semantic function for the `PP -> PPLACE` production ought to just be the identity function. Let's check."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pp_place_production = list(augmentations_4.keys())[2]\n", "pp_place_production"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pp_place_augmentation = augmentations_4[pp_place_production]\n", "pp_place_augmentation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for x in [42, 'hello', True]:\n", "  print(pp_place_augmentation(x))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So it sure looks like the augmentation for the `PP -> Place` rule is doing what we asked. (If not, check over your solution to the augmented grammar.)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Applying the grammar\n", "With augmented grammar in hand, we can use it to get a FOL meaning representation for sentences. The procedure has two steps:\n", "\n", "1. Run a syntactic parsing algorithm to get a syntactic tree. \n", "2. Follow the tree derivation to obtain a meaning representation. \n", "\n", "The first step you're familiar with from the last segment of the course; this is the role of parsing algorithms such as CKY.\n", "\n", "The second step works by walking the tree, recursively constructing meanings for the subconstituents of a node, and then combining those subconstituent meanings by applying the production augmentation for the node to the subconstituent meanings to construct the meaning of the tree itself. This recursive method bottoms up when we come to a tree that has no nonterminal subconstituents; we just apply its production augmentation to the empty set of arguments.\n", "\n", "You could implement such a function \u2013 in fact, you will in project segment 4 \u2013 but for purpose of the lab today, you'll just carry out this process by hand.\n", "\n", "Let us walk through a semantic parsing of the expression \"flights from Boston\". First, we construct a syntactic parse tree for this sentence. The following function makes an `nltk` syntactic grammar from the syntactic-semantic grammar:\n", "\n", "We can use `nltk`'s parser to parse the sentence:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parser = nltk.parse.BottomUpChartParser(grammar_4)\n", "\n", "sentence = \"flights from Boston\".split()\n", "for tree in [p for p in parser.parse(sentence)]:\n", "    tree.pretty_print()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Below, we use variables like `A__some_words` to store the meaning for the constituent with nonterminal \"A\" spanning \"some words\".   \n", "\n", "For example, for the subtree `(NP 'flights')` at the bottom left of the tree, we'll store its meaning in the variable `NP__flights`. That meaning is constructed by applying the augmentation for the production `NP -> 'flights'` to the empty set of arguments. Hopefully, in the grammars starting with `grammar_spec_1` above, you've had the augmentation for that rule as `lambda: lambda x: x in Flight`. Applying this to the empty set of arguments, we get `(lambda: lambda x: x in Flight)()`, that is, `lambda x: x in Flight`.\n", "We record this for purposes of the lab as:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["NP__flights = (lambda: lambda x: x in Flight)()"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Now do the same for the subtree rooted in `LOC`.\n", "<!--\n", "BEGIN QUESTION\n", "name: derivation_1\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO\n", "LOC__Boston = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"derivation_1\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Working bottom up, we consider the subtree rooted in `PP_PLACE`. What is the augmentation for the production used to form that subtree? Apply the augmentation to the meaning you've just computed for its one nonterminal-rooted subconstituent, which you've already stored as `LOC__Boston`, and call the result as `PP_PLACE__from_Boston`.\n", "<!--\n", "BEGIN QUESTION\n", "name: derivation_2\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO\n", "PP_PLACE__from_boston = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"derivation_2\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Again working bottom up, define the meaning for PP, by applying the meaning of the rule `PP -> PP_PLACE` to the meaning of the `PP_PLACE` just computed.\n", "<!--\n", "BEGIN QUESTION\n", "name: derivation_3\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO\n", "PP__from_boston = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"derivation_3\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Finally, derive the meaning of the entire expression by applying the meaning of the rule `NP -> NP PP` to the meanings of its parts. \n", "<!--\n", "BEGIN QUESTION\n", "name: derivation_4\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO\n", "NP__flights_from_boston = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"derivation_4\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To check that you've got the correct expression, we run through all objects in the flight world and apply the expression to them, printing out the ones that evaluate to `True`. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print([obj for obj in Object if NP__flights_from_boston(obj)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If your grammar augmentations are correct and you've carried out the deribvation correctly, you should get a list of just those objects that are flights from Boston, namely, DL10 and DL11.\n", "\n", "Let's move to a more complex example. Now that you know the drill, construct the meaning for \"flights from Boston to New York\" using the same augmented grammar grammar. Here's the parse tree:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sentence = \"flights from Boston to New York\".split()\n", "parses = [p for p in parser.parse(sentence)]\n", "for tree in parses:\n", "    tree.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Create the meaning representation by walking through the tree bottom up. You can use the result you got for \"flights from Boston\" and compose it with the rest of the expression. The result will be stored as `NP__flights_from_boston_to_new_york`.\n", "<!--\n", "BEGIN QUESTION\n", "name: derivation_5\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO\n", "NP__flights_from_boston_to_new_york = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"derivation_5\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now run the expression against the flight world to verify you got the correct result:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print([obj for obj in Object if NP__flights_from_boston_to_new_york(obj)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Scaling up\n", "Constructing the meaning representation manually by traversing a tree is a tedious process. In practice, we would like an automated process, which, given any syntactic-semantic grammar and a tree consistent with the syntactic grammar returns a semantic representation. So far, we've seen how to use the syntactic parse tree to guide the composition of semantic representations. In project segment 4, you will automate this process by implementing such a generic semantic parser, which takes any tree with associated semantic rules, and constructs the meaning representation, doing just the work you've been doing by hand here."]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "---\n", "\n", "## Lab debrief \u2013 for consensus submission only\n", "\n", "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n", "\n", "* Was the lab too long or too short?\n", "* Were the readings appropriate for the lab? \n", "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n", "* Are there additions or changes you think would make the lab better?\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_debrief\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "# End of Lab 4-1"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["---\n", "\n", "To double-check your work, the cell below will rerun all of the autograder tests."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check_all()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}, "title": "CS187 Lab 4-1: First-order logic, lambda calculus, semantic parsing"}, "nbformat": 4, "nbformat_minor": 4}