{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false, "jupyter": {"outputs_hidden": true, "source_hidden": true}}, "outputs": [], "source": ["# Please do not change this cell because some hidden tests might depend on it.\n", "import os\n", "\n", "# Otter grader does not handle ! commands well, so we define and use our\n", "# own function to execute shell commands.\n", "def shell(commands, warn=True):\n", "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n", "     \n", "       Prints the result to stdout and returns the exit status. \n", "       Provides a printed warning on non-zero exit status unless `warn` \n", "       flag is unset.\n", "    \"\"\"\n", "    file = os.popen(commands)\n", "    print (file.read().rstrip('\\n'))\n", "    exit_status = file.close()\n", "    if warn and exit_status != None:\n", "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n", "    return exit_status\n", "\n", "shell(\"\"\"\n", "ls requirements.txt >/dev/null 2>&1\n", "if [ ! $? = 0 ]; then\n", " rm -rf .tmp\n", " git clone https://github.com/cs236299-2020/lab1-5.git .tmp\n", " mv .tmp/tests ./\n", " mv .tmp/requirements.txt ./\n", " rm -rf .tmp\n", "fi\n", "pip install -q -r requirements.txt\n", "\"\"\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["# Initialize Otter\n", "import otter\n", "grader = otter.Notebook()"]}, {"cell_type": "raw", "metadata": {}, "source": ["%%latex\n", "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\newcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\newcommand{\\softmax}{\\operatorname{softmax}}\n", "\\newcommand{\\Prob}{\\Pr}\n", "\\newcommand{\\given}{\\,|\\,}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$$\n", "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n", "\\renewcommand{\\Prob}{\\Pr}\n", "\\renewcommand{\\given}{\\,|\\,}\n", "$$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Course 236299\n", "## Lab 1-5 \u2013 Scaling up: Torchtext and PyTorch\n", "\n", "The pipeline for NLP applications based on supervised machine learning involves several standard components:\n", "\n", "1. Loading of annotated textual corpora.\n", "2. Tokenization and normalization of the text.\n", "3. Distributing instances into subcorpora, for instance, training, development, and test corpora.\n", "4. Training of models on training data, using development data for model selection.\n", "5. Evaluation of the models on test data.\n", "\n", "Rather than recapitulate all of these component tasks for each application, standard packages have been developed to facilitate them. In order to facilitate your own experimentation, it's time to make use of some of these packages to scale up your ability to build and test models. That is the subject of this lab.\n", "\n", "Torchtext datasets provide a uniform system for establishing dataset objects that contain multiple examples, each of which may have multiple named fields. These fields themselves have specifications that tell whether the data in that field is sequential (like text sequences) or simple (like class labels); whether and how to preprocess, tokenize, or postprocess the data; and many other properties. Dataset objects can be easily split into parts (training and test, for instance), or turned into a sequence of small batches for processing by models.\n", "\n", "This lab provides an introduction to using `torchtext` and PyTorch in preparation for its appearance in later labs and project segments.\n", "\n", "After this lab, you should be able to\n", "\n", "* Read `torchtext` code and understand what it is intending to accomplish.\n", "* Run experiments training and testing simple feed-forward neural networks using PyTorch."]}, {"cell_type": "markdown", "metadata": {}, "source": ["New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n", "\n", "* [`torch.Tensor.backward`](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.backward)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preparation \u2013 Loading packages and data"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["import copy\n", "import math\n", "import random\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import os\n", "import re\n", "import sys\n", "import torch\n", "import torch.distributions as ds\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torchtext as tt\n", "import warnings\n", "\n", "from torch import optim"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n", "plt.style.use('tableau-colorblind10')\n", "\n", "# Random seed\n", "random_seed = 1234\n", "random.seed(random_seed)\n", "torch.manual_seed(random_seed)\n", "## GPU check\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "print(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Turn off annoying torchtext warnings about pending deprecations\n", "warnings.filterwarnings(\"ignore\", module=\"torchtext\", category=UserWarning)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Part 1: Manipulating text corpora with `torchtext`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You'll use `torchtext` to load the _Green Eggs and Ham_ (GEaH) dataset.\n", "\n", "We start with reading in the data and performing some ad hoc cleaning (removing comment lines and blank lines)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def strip_file(text):\n", "    \"\"\"strip #comments and empty lines from `text` string\"\"\"\n", "    result = \"\"\n", "    for line in text.split(\"\\n\"):\n", "        line = line.strip()              # trim whitespace\n", "        line = re.sub('#.*$', '', line)  # trim comments\n", "        if line != '':                   # drop blank lines\n", "            result += line + '\\n'\n", "    return result\n", "\n", "# Read the GEaH data and write out a corresponding TSV file\n", "shell('wget -nv -N -P data \"https://github.com/nlp-236299/data/raw/master/Seuss/seuss - 1960 - green eggs and ham.txt\"')\n", "with open('data/seuss - 1960 - green eggs and ham.txt', 'r') as fin:\n", "    with open('data/geah.tsv', 'w') as fout:\n", "        fout.write(strip_file(fin.read()))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Constructing training and test datasets\n", "\n", "Take a look at the file `geah.tsv`, which we've just processed and placed into the sibling `data` folder. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shell('head \"data/geah.tsv\"')"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Notice the structure of this corpus. Each line contains a sentence from the book, preceded by a label that provides the speaker of that sentence. The speaker and sentence are separated by a tab character. The data is thus set up properly for a [`torchtext.data.TabularDataset`](https://pytorch.org/text/data.html#torchtext.data.TabularDataset) using its `\"TSV\"` (tab-separated values) format.\n", "\n", "We call each such pair of (sentence, speaker) an *example* or an *instance*. An instance is an example in the dataset, and the dataset contains a set of instances/examples. In this lab, an instance is a sentence paired with its label (the speaker).\n", "\n", "In order to establish a `torchtext.data.TabularDataset` object for dealing with the GEaH dataset, you'll first need to establish the two fields (via [`torchtext.data.Field`](https://pytorch.org/text/data.html#field)), one for the label (the speaker) and one for the text, which you should call `LABEL` and `TEXT`, respectively. These fields are used for mapping from strings to ids or vice versa, which we'll use for problem set 1.\n", "\n", "When setting up a field with `torchtext.data.Field`, you'll want to consider whether you want to further specify the values for the various keyword arguments listed [here](https://torchtext.readthedocs.io/en/latest/data.html#field), or to leave the default values.\n", "\n", "> You may see generated messages warning that the Field class or other parts of `torchtext` are deprecated. You can ignore these warnings. We're using the legacy `torchtext` interface rather than the one taking over in the next `torchtext` release.\n", "\n", "With respect to the tokenization of the text field, you should use the `torchtext` \"basic_english\" tokenizer introduced in lab 1-1 for the text field and lowercase all tokens. Note the `sequential` optional argument for `torchtext.data.Field` - the labels are not sequential (why?), and the text is sequential.\n", "<!--\n", "BEGIN QUESTION\n", "name: fields_setup\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO: Define one `tt.data.Field` for processing the label\n", "# and another for processing the text using the \"basic_english\"\n", "# tokenizer and **lowercase** all tokens\n", "LABEL = (\n", "    ...\n", ")\n", "    \n", "TEXT = (\n", "    ...\n", ")\n", "fields = [(\"label\", LABEL), (\"text\", TEXT)]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"fields_setup\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Now, you can set up the dataset using [`torchtext.data.TabularDataset`](https://pytorch.org/text/data.html#torchtext.data.TabularDataset). It should look for the `TSV` format data in the file `data/geah.tsv`, and should use the `fields` defined above.\n", "<!--\n", "BEGIN QUESTION\n", "name: dataset_setup\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO: Set up the dataset using `tt.data.TabularDataset`\n", "# Note that you need to use `fields` for fields.\n", "geah = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"dataset_setup\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["All [`torchtext.data.Dataset`](https://pytorch.org/text/data.html#torchtext.data.Dataset) objects have a [`split`](https://pytorch.org/text/data.html#torchtext.data.Dataset.split) method that splits the dataset into two or three pieces, for instance, to have a separate training and test set. Use the `split` method to generate a 70%/30% split of the GEaH corpus into two subsets called `train` and `test`.\n", "<!--\n", "BEGIN QUESTION\n", "name: dataset_split\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO: Split geah into 70% training data and 30% test data\n", "train, test = \\\n", "    ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"dataset_split\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fields can have associated with them a _vocabulary_ consisiting of all of the possible values that are used in that field in a particular dataset. The vocabulary establishes the kind of indexing scheme between types and indices that we explored in lab 1-1. We will use the training corpus to establish vocabularies for the two fields `LABEL` and `TEXT` using the [`build_vocab`](https://pytorch.org/text/data.html#torchtext.data.Field.build_vocab) method."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LABEL.build_vocab(train.label)\n", "TEXT.build_vocab(train.text)"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["The `TEXT` and `LABEL` fields, objects of class [`torchtext.data.Field`](https://pytorch.org/text/data.html#field), now have vocabularies associated with them, accessible in their respective `vocab` fields. How many elements are there in these vocabularies? You can use the `len` function to find out.\n", "<!--\n", "BEGIN QUESTION\n", "name: vocab_sizes\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO: Calculate the sizes of LABEL.vocab and TEXT.vocab\n", "label_vocab_size = ...\n", "text_vocab_size = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"vocab_sizes\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"label vocabulary size is {label_vocab_size}\\n\"\n", "      f\"text vocabulary size is {text_vocab_size}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Why are there three elements in the `LABEL` vocabulary, given that there are only two speakers, Guy and Sam? We can find out by examining the `LABEL` vocabulary more closely. `Field` vocabulary objects have an especially useful `stoi` data field, whose value is a dictionary that maps the elements of the vocabulary to integer index representations of the elements. Let's take a look."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LABEL.vocab.stoi"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "**Question:** What is the unexpected third element in the label vocabulary? Why do you think it's there?\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_third_element\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "> As described in more detail in [the `torchtext` documentation](https://torchtext.readthedocs.io/en/latest/vocab.html#torchtext.vocab.Vocab), there's also an `itos` data field for conversion of vocabulary items from the index representation to the original values and a `freqs` data field that keeps a frequency distribution for the items in the vocabulary as a `collections.Counter` object."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Operations over datasets\n", "\n", "We now have training and test datasets. You can experiment with the kinds of operations you'll need to do to implement models like Naive Bayes or logistic regression.\n", "\n", "For instance, you can inspect an example from the dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["example = train[1] # the second instance\n", "print (f\"text: {example.text}\\n\"\n", "       f\"label: {example.label}\")"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["You might also need to iterate over the different class labels (the vocabulary of the `LABEL` field) or the word types (the vocabulary of the `TEXT` field). Define a function that iterates over the vocabulary of a field and prints each one out like this:\n", "\n", "```\n", ">>> print_vocab(LABEL)\n", "<unk>\n", "GUY\n", "SAM\n", "```\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: print_vocab\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO\n", "def print_vocab(field):\n", "    ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"print_vocab\")"]}, {"cell_type": "markdown", "metadata": {}, "source": [" We can use the `print_vocab` function to print out the different class labels in the `LABEL` field."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print_vocab(LABEL)"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["Other simple calculations that will be useful in implementing the various models:\n", "\n", "1. Counting how many instances there are in a dataset.\n", "2. Counting how many instances of a certain class there are in a dataset.\n", "3. Counting how many tokens of a certain type there are in the text of an instance.\n", "\n", "Let's write functions for these. They'll come in handy in the first problem set.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: count_instances\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO - 1. Counting how many instances there are in a dataset.\n", "def count_instances(dataset):\n", "    ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"count_instances\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO - 2. Counting how many instances of a certain class there are in a dataset.\n", "def count_instances_class(dataset, label):\n", "    ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"count_instances_class\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#TODO - 3. Counting how many tokens of a certain type there are in the text of an instance.\n", "# Note: recall that you can access the list of tokens using `instance.text`\n", "def count_tokens_instance(instance, tokentype):\n", "    ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"count_tokens_instances\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Recall that the purpose of fields is to map back and forth between strings and word ids. Below provides an example of how to do that."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["example = train[1]\n", "text = example.text\n", "word_ids = [TEXT.vocab.stoi[word] for word in text]\n", "print (f\"Mapped to word ids: {word_ids}\\n\"\n", "       f\"Mapped back: {[TEXT.vocab.itos[id] for id in word_ids]}\")\n", "label = example.label\n", "label_id = LABEL.vocab.stoi[label]\n", "print (f\"Label id: {label_id}\\n\"\n", "       f\"label: {LABEL.vocab.itos[label_id]}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Part 2: Training and testing with PyTorch\n", "\n", "Past labs have shown that all of the detail about \n", "\n", "* establishing models and their parameters,\n", "* using them to calculate the outputs for some inputs, \n", "* training them to optimize the parameters via stochastic gradient descent, and \n", "* evaluating them by testing on held-out data\n", "\n", "is tedious to manage. Fortunately, it is also so formulaic, at least for a certain class of models, that general tools can be deployed to manage the process. In the remainder of this lab, you'll use one such tool, PyTorch. For simplicity, rather than a natural-language task, you'll be training a model to fit a curve; it has an especially simple structure: one scalar input and one scalar output."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Generating training and test data\n", "\n", "We start by generating some training and test data. The data is generated as a noisy sine function, calculated by the function `sinusoid`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sinusoid(x, amplitude=1., phase=0., frequency=1., noise=0.):\n", "    \"\"\"Returns the values on input(s) `x` of a sinusoid determined by `amplitude`, \n", "       `phase`, and angular `frequency`, with some added normal noise with variance \n", "       given by `noise`.\"\"\"\n", "    normal_noise = ds.normal.Normal(torch.tensor([0.0]), torch.tensor([noise]))\n", "    noise_sample = torch.tensor([normal_noise.sample() for i in range(len(x))])\n", "    y = amplitude * torch.sin(x * frequency + phase) + noise_sample\n", "    return y"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can generate data for training and testing by sampling this function."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sample_input(func, count, bound, **kwargs):\n", "    \"\"\"Returns `count` samples of x-y pairs of function `func`, with the x \n", "       values sampled uniformly between +/-`bound`. The `kwargs` are passed\n", "       on to `func`.\"\"\"\n", "    input_unif = ds.uniform.Uniform(-bound, +bound)\n", "    x = input_unif.sample(torch.Size([count]))\n", "    y = func(x, **kwargs)\n", "    return x, y"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To give a sense of what a data sample looks like, we plot a sample of 100 points."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_sample(data):\n", "    \"\"\"Plots `data` given as a single pair of inputs and outputs.\"\"\"\n", "    X, Y = data\n", "    plt.plot(X.numpy(), Y.numpy(), '.')\n", "    plt.xlabel('Input')\n", "    plt.ylabel('Output')\n", "    # we cannot use plt.show() because otter-grader does not support it"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_sample(sample_input(sinusoid, 100, 5, noise=0.1))"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["## Specifying a feed-forward neural network\n", "\n", "\n", "<img src=\"https://github.com/nlp-236299/data/raw/master/Resources/ffnn-example.png\" width=33% align=right />\n", "\n", "The model that we will train to predict the output of this function based on a sample will consist of a series of sublayers as depicted in the figure at right. At the bottom of the figure, we start with $\\vect{x}$, the scalar input (of dimensionality $1$ as shown in the \"shape\" designation). The first layer is a perceptron layer, with a linear sublayer (with weights $\\vect{U}$) followed by a sigmoid sublayer. Since $U$ is of dimensionality $1 \\times D$, the output is a vector of dimensionality $D$. (We refer to $D$ as the hidden dimension.) Then comes another perceptron layer with output of dimensionality $D$. Finally, a single linear layer reduces the dimensionality back to the predicted scalar output $\\tilde{y}$ of dimensionality $1$. The loss is calculated as the mean square error of $\\tilde{y}$ relative to $y$. (In this case, taking the mean for a single example is irrelevant, since $y$ is a scalar, though for batches, the mean will be taken over the batch.)\n", "\n", "We define a class `FFNN` (**f**eed-**f**orward **n**eural **n**etwork), which inherits from the `nn.Module` class, PyTorch's class for neural network models. It takes an argument `hidden_dim` which is the size of the hidden layers, $D$ in the figure.\n", "\n", "The parameters of this model \u2013 the values that will be adjusted to minimize the loss \u2013 are the elements of the tensors $\\vect{U}$, $\\vect{V}$, and $\\vect{W}$. Those parameters are created and tracked when the corresponding sublayers are created using `nn.Linear`. That's the wonder of using PyTorch \u2013 so much happens under the hood.\n", "\n", "The computation that the `FFNN` class performs is defined in the `forward` function. We have already implemented the computation of the first perceptron, that is, a linear sub-layer `sublayer1` followed by a sigmoid sub-layer `sublayer2`. The intermediate output is stored in `z`. We have also implemented the computation of the last layer, the linear layer `sublayer5`, which takes as input `z_prime`. Complete the computation of `forward` by filling in the missing part: a perceptron that takes `z` as input, runs a linear sub-layer `sublayer3`, a sigmoid sub-layer `sublayer4`, and assigns the result to `z_prime`.  \n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: forward_step\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class FFNN(nn.Module):\n", "    def __init__(self, hidden_dim, init_low=-2, init_high=2):\n", "        super().__init__()\n", "        # dimensionality of hidden layers\n", "        self.hidden_dim = hidden_dim\n", "        # establishing the sublayers -- two perceptrons and a final\n", "        # linear layer -- and their parameters\n", "        self.sublayer1 = nn.Linear(1, hidden_dim)          # U: 1 X D\n", "        self.sublayer2 = nn.Sigmoid() \n", "        self.sublayer3 = nn.Linear(hidden_dim, hidden_dim) # V: D X D\n", "        self.sublayer4 = nn.Sigmoid() \n", "        self.sublayer5 = nn.Linear(hidden_dim, 1)          # W: D X 1\n", "        \n", "        # initialize parameters randomly\n", "        torch.manual_seed(random_seed)\n", "        for p in self.parameters():\n", "            p.data.uniform_(init_low, init_high)\n", "        # save a copy of the parameters to allow resetting\n", "        self.init_state = copy.deepcopy(self.state_dict())\n", "\n", "    # Resetting state: If you want to rerun a model, say, with a different\n", "    # training regime, you can reset the model's parameter state using\n", "    #    model.reset_state()\n", "    # before retraining, e.g., \n", "    #    train_model(model, criterion, optim, train_data, n_epochs=50)\n", "    def reset_state(self):\n", "        self.load_state_dict(copy.deepcopy(self.init_state))\n", "        \n", "    def forward(self, x):\n", "        # first perceptron layer\n", "        z = self.sublayer2(self.sublayer1(x))\n", "        # second perceptron layer\n", "        z_prime = ...\n", "        # final linear layer\n", "        return self.sublayer5(z_prime)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can build a model by instantiating the `FFNN` class. We'll do so with a hidden dimension of 4, being careful to move the model with its parameters to the device we're using for calculations (a GPU if one is available, as on Google Colab)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["HIDDEN_DIMENSION = 4\n", "model = FFNN(HIDDEN_DIMENSION).to(device)"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["We can feed the model a scalar (tensor of size 1) input `x` and get a scalar output `y`. \n", "<!--\n", "BEGIN QUESTION\n", "name: forward_step\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = torch.Tensor([1.])\n", "with torch.no_grad():\n", "    y = model(x)\n", "print(f\"x: {x}, y: {y}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"forward_step\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We specify the criterion to be optimized as the mean square error loss function provided by PyTorch."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.MSELoss(reduction='mean') "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluating data according to a model\n", "\n", "To evaluate how well the model performs on some test data, we run the model forward on the $x$ values and compute the loss relative to the $y$ values. We define a function `eval_model` to carry out this calculation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def eval_model(model, criterion, data):\n", "    \"\"\"Applies the `model` to the x values in the `data` and returns the\n", "       loss relative to the y values in the `data` along with the predicted \n", "       y values.\"\"\"\n", "    model.eval()                          # turn on evaluation mode\n", "    with torch.no_grad():                 # turn off propagating gradients\n", "        X, Y = data                       # extract x and y values\n", "        X = X.view(-1, 1).to(device)      # convert x and y to column vectors\n", "        Y = Y.view(-1, 1).to(device)      # ...and move them to the device\n", "        predictions = model(X)            # calculate the predicted y values\n", "        loss = criterion(predictions, Y)  # see how far off they are\n", "    return loss.item(), predictions"]}, {"cell_type": "markdown", "metadata": {}, "source": ["All that remains is training the model. We'll use one of PyTorch's built in optimizers, the `Adam` optimizer. We set a few parameters for the training process: the learning rate, the number of \"epochs\" (passes through the training data) to perform, and the number of examples to train on at a time (the \"batch size\")."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Parameters of the training regimen\n", "LEARNING_RATE = 0.003\n", "NUMBER_EPOCHS = 25\n", "BATCH_SIZE = 20\n", "\n", "## Choices for optimizers:\n", "\n", "# Stochastic Gradient Descent (SGD) optimizer\n", "# optim = torch.optim.SGD(model.parameters(), lr = learning_rate)\n", "\n", "# The Adam optimizer, as described in the paper:\n", "# Kingma and Ba. 2014. Adam: A Method for Stochastic Optimization.\n", "# [https://arxiv.org/abs/1412.6980]\n", "optim = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Training the parameters of a model\n", "\n", "Finally, we get to the function to train the parameters of the model so as to best fit the predictions to the actual values. We've provided the code, except for a few lines that you'll need to provide (marked `#TODO`), making use of some of the tools defined above. Those lines, which form the heart of the computation, calculate \"forwards\" to get the output predictions for the inputs, calculate the loss for those predictions, and calculate \"backwards\" the gradients of the loss for each of the parameters of the model. This sets up the optimizer to take a step of updating the parameters, making use of the calculated gradients to determine the direction to step. The saved gradients can then be zeroed and the process repeated.\n", "\n", "> Note: The code we're asking you to write is *tiny*. If you find yourself writing more than a short line of code per `#TODO`, you're missing something. If you need help, take a look at the example in Section 4: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#train-the-network"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(model, criterion, optimizer, data,\n", "                n_epochs=NUMBER_EPOCHS, batch_size=BATCH_SIZE):\n", "    \"\"\"Optimizes the parameters of the `model` by minimizing the `criterion`\n", "       on the training `data`, using the `optimizer` algorithm for updates.\"\"\"    \n", "    model.train()                     # Turn on training mode\n", "\n", "    X, Y = data\n", "    trainX_len = len(X)\n", "    \n", "    for epoch in range(n_epochs):\n", "        loss_per_epoch = 0.\n", "        for batch_i in range(int(trainX_len/batch_size)):\n", "            optimizer.zero_grad()     # new batch; zero the gradients of the parameters\n", "            \n", "            # Input tensors and their corresponding output values for this batch\n", "            inputs = (X[batch_i * batch_size\n", "                         : (batch_i+1) * batch_size] # extract examples in batch\n", "                       .view(-1, 1)                  # reshape to column vector\n", "                       .to(device)                   # move to device\n", "                      )\n", "            labels = (Y[batch_i * batch_size \n", "                         : (batch_i+1) * batch_size]\n", "                       .view(-1, 1)\n", "                       .to(device)\n", "                      )\n", "            \n", "            #TODO: Calculate outputs for the x values in this batch\n", "            outputs = ...\n", "            \n", "            #TODO: Calculate the loss for the outputs\n", "            loss = ...\n", "            \n", "            #TODO: Perform backpropagation to calculate gradients\n", "            ...\n", "            \n", "            # Update all parameters\n", "            optimizer.step()\n", "            \n", "            loss_per_epoch += loss.item()\n", "        \n", "        print(f\"Epoch: {epoch+1:3d}  Total loss: {loss_per_epoch:8.3f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Putting it all together\n", "\n", "Let's try it out. We start by generating some training and test data. The training data will be 10,000 samples of a noisy sinusoid. The test data, 100 samples from the same sinusoid, will be noise-free, so we can see how close the predictions are to noise-free outputs."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_data = sample_input(sinusoid, 10000, 5., frequency=1.5, noise=0.05)\n", "test_data = sample_input(sinusoid, 100, 5., frequency=1.5)\n", "\n", "plot_sample(train_data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We train the model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.reset_state()\n", "train_model(model, criterion, optim, train_data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["...and test the trained model by evaluating it on the the test data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loss, predictions = eval_model(model, criterion, test_data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"model_reduces_loss\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can see how well the model works by plotting the test data (circles) along with the predicted values (crosses)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def visualize_predictions(data, predictions):\n", "    X, Y = data\n", "    \n", "    # Plot the actual output values\n", "    plt.plot(X.cpu().numpy(), Y.cpu().numpy(), '.', label = 'Target Values')\n", "    \n", "    # Plot the predicted output values\n", "    predictions = predictions.view(-1, 1)\n", "    plt.plot(X.cpu().numpy(), predictions.cpu().numpy(), 'x', label = 'Predictions')\n", "    \n", "    plt.xlabel('Input')\n", "    plt.ylabel('Output')\n", "    plt.legend()\n", "    # we cannot use plt.show() because otter-grader does not support it"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualize the predictions\n", "visualize_predictions(test_data, predictions)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Trying different models\n", "\n", "Now that we have the infrastructure, try experimenting with different models. Here are a few things you might play with. (No need to try them all.) What happens if you change the hidden dimension, increasing it to 8 or decreasing it to 2? What happens if you drop the middle layer? What about no middle layer but a much higher hidden dimension size? Does running for more epochs improve performance? Does the SGD optimizer work better or worse than the Adam optimizer?\n", "\n", "**Perform any experimentation in cells below this point, so you don't modify the cells above that are being unit tested.**"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "**Question:** What conclusions have you drawn from your experimentation?\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_testing_models\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- END QUESTION -->\n", "\n", "<!-- BEGIN QUESTION -->\n", "\n", "## Lab debrief \u2013 for consensus submission only\n", "\n", "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n", "\n", "* Was the lab too long or too short?\n", "* Were the readings appropriate for the lab? \n", "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n", "* Are there additions or changes you think would make the lab better?\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_debrief\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "# End of lab 1-5"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["---\n", "\n", "To double-check your work, the cell below will rerun all of the autograder tests."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check_all()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}, "title": "CS187 Lab 1-5: Scaling up: Torchtext and PyTorch"}, "nbformat": 4, "nbformat_minor": 4}