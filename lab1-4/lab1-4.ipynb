{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"title":"CS187 Lab 1-4: Discriminative methods for classification","colab":{"name":"lab1-4.ipynb","provenance":[],"collapsed_sections":["OeLmgsPKlyiH","VzmLDXPOlyiO"]}},"cells":[{"cell_type":"code","metadata":{"deletable":false,"editable":false,"jupyter":{"outputs_hidden":true,"source_hidden":true},"id":"uVdEqoealycZ","executionInfo":{"status":"ok","timestamp":1605110619586,"user_tz":-120,"elapsed":7165,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"72a51fd5-2259-4641-9115-0e18448acd51","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Please do not change this cell because some hidden tests might depend on it.\n","import os\n","\n","# Otter grader does not handle ! commands well, so we define and use our\n","# own function to execute shell commands.\n","def shell(commands, warn=True):\n","    \"\"\"Executes the string `commands` as a sequence of shell commands.\n","     \n","       Prints the result to stdout and returns the exit status. \n","       Provides a printed warning on non-zero exit status unless `warn` \n","       flag is unset.\n","    \"\"\"\n","    file = os.popen(commands)\n","    print (file.read().rstrip('\\n'))\n","    exit_status = file.close()\n","    if warn and exit_status != None:\n","        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n","    return exit_status\n","\n","shell(\"\"\"\n","ls requirements.txt >/dev/null 2>&1\n","if [ ! $? = 0 ]; then\n"," rm -rf .tmp\n"," git clone https://github.com/cs236299-2020/lab1-4.git .tmp\n"," mv .tmp/tests ./\n"," mv .tmp/requirements.txt ./\n"," rm -rf .tmp\n","fi\n","pip install -q -r requirements.txt\n","\"\"\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"Cgv0jmGNlydN","executionInfo":{"status":"ok","timestamp":1605110619857,"user_tz":-120,"elapsed":7402,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["# Initialize Otter\n","import otter\n","grader = otter.Notebook()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U92PmykAlydW"},"source":["%%latex\n","\\newcommand{\\vect}[1]{\\mathbf{#1}}\n","\\newcommand{\\cnt}[1]{\\sharp(#1)}\n","\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n","\\newcommand{\\softmax}{\\operatorname{softmax}}\n","\\newcommand{\\Prob}{\\Pr}\n","\\newcommand{\\given}{\\,|\\,}"]},{"cell_type":"markdown","metadata":{"id":"5LWDFpa6lydX"},"source":["$$\n","\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n","\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n","\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n","\\renewcommand{\\softmax}{\\operatorname{softmax}}\n","\\renewcommand{\\Prob}{\\Pr}\n","\\renewcommand{\\given}{\\,|\\,}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"gFVMu9GNlydZ"},"source":["# Course 236299\n","## Lab 1-4 – Discriminative methods for classification"]},{"cell_type":"markdown","metadata":{"id":"U-RaJgAZlyda"},"source":["In this lab, you'll apply a discriminative classification method to the _Federalist_ papers' authorship attribution problem, the logistic regression (perceptron) model. \n","\n","After this lab, you should be able to\n","\n","* Derive the basic equations for the logistic regression classification method;\n","* Perform the forward computation to generate the class that a logistic regression model predicts for some input;\n","* Calculate a loss for that prediction, the cross-entropy loss;\n","* Update the parameters of a logistic regression model by stochastic gradient descent."]},{"cell_type":"markdown","metadata":{"id":"AkwHZiQXlydc"},"source":["New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n","\n","* `numpy.exp`"]},{"cell_type":"markdown","metadata":{"id":"tXeNMrSglydd"},"source":["## Preparation – Loading packages and data"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"F3G6iK0Xlydf","executionInfo":{"status":"ok","timestamp":1605110619859,"user_tz":-120,"elapsed":7394,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["# Please do not change these imports because some hidden tests might depend on them.\n","# You can add a cell below if you need to import anything else.\n","import json\n","import math\n","import matplotlib\n","import matplotlib.pyplot as plt\n","matplotlib.style.use('tableau-colorblind10')\n","import numpy as np\n","import os\n","\n","from math import log2\n","from pprint import pprint"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"73GxoHBQlydu","executionInfo":{"status":"ok","timestamp":1605110620409,"user_tz":-120,"elapsed":7928,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"caaa9cdc-3425-4c81-a83e-c4fbbb81a70b","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Download and read the Federalist data from the json file\n","shell('wget -nv -N -P data https://github.com/nlp-236299/data/raw/master/Federalist/federalist_data.json')\n","with open('data/federalist_data.json', 'r') as fin:\n","    dataset = json.load(fin)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_KRtoVfPlyd3","executionInfo":{"status":"ok","timestamp":1605110620414,"user_tz":-120,"elapsed":7914,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["# As before, we extract the papers by either of Madison and Hamilton \n","# to serve as training data.\n","training = list(filter(lambda ex: ex['authors'] in ['Madison', 'Hamilton'],\n","                       dataset))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SnGoT-8UlyeB"},"source":["## Logistic regression\n","\n","You've read about logistic regression, a method for classification that is discriminative rather than generative. Like the generative Naive Bayes method, each example is characterized by a vector of features (the counts of word types for a text, say, as for the _Federalist_ example that we've been using). In logistic regression, each such feature is assigned a weight, and the score for an example is given by weighting each feature value by its weight and summing the result; that is, the score is the dot product of the feature vector and the weight vector. Let's take an example, one of the Federalist papers. We'll extract from the training data the counts for the first example in the training set. That's the feature vector for this example."]},{"cell_type":"code","metadata":{"id":"iAydQuH6lyeJ","executionInfo":{"status":"ok","timestamp":1605110620436,"user_tz":-120,"elapsed":7926,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"0bdfac69-2ee7-4445-9620-de68bfdda7ca","colab":{"base_uri":"https://localhost:8080/"}},"source":["training0_counts = training[0]['counts']\n","training0_counts"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[9, 6, 2, 0]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"_sOluTUvlyeR"},"source":["Suppose the weights for the features are as given by the following vector:"]},{"cell_type":"code","metadata":{"id":"NkcEq5BKlyeW","executionInfo":{"status":"ok","timestamp":1605110620439,"user_tz":-120,"elapsed":7899,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["weights = [-.1, .2, .3, -1]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"gN4Bmwkulyeg"},"source":["What would the weighted sum of the counts with these weights be? Feel free to use `np.dot` to take the dot product for you.\n","<!--\n","BEGIN QUESTION\n","name: wtd_sum\n","-->"]},{"cell_type":"code","metadata":{"id":"nactE2lYlyeo","executionInfo":{"status":"ok","timestamp":1605110620441,"user_tz":-120,"elapsed":7892,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO: Take the weighted sum of `training0_counts` with `weights`\n","w, tr0_c = np.array(weights), np.array(training0_counts)\n","wtd_sum = np.dot(w, tr0_c)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"0rHIs7eclyez","executionInfo":{"status":"ok","timestamp":1605110620444,"user_tz":-120,"elapsed":7867,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"66751dbd-30e4-4e88-e61e-5be1cc7879b4","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"wtd_sum\")"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"09DB1dcNlye7"},"source":["<!-- BEGIN QUESTION -->\n","\n","**Question:** What is the range of possible values that such a weighted sum can take on?\n","<!--\n","BEGIN QUESTION\n","name: open_response_possible_sums\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"M-IjsJBslye8"},"source":["It can be any real number as a multiplication of any real numbers."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"rZpDujPGlye9"},"source":["<!-- END QUESTION -->\n","\n","In order to have a standard way of comparing these numbers, it helps to be able to place them on a fixed scale, from 0 to 1, say. This way, they can be interpreted as probabilities. We use the _logistic function_ ($\\sigma$) to carry out this conversion:\n","\n","$$ \\sigma(x) = \\frac{1}{1 + e^{-k x}}$$\n","\n","In addition to its argument $x$, the function takes an additional parameter $k$, which we will explore shortly.\n","\n","Define a function `sigma` implementing the logistic function. (We've established a default value for `k` of 1 in the header line below.)\n","<!--\n","BEGIN QUESTION\n","name: sigma\n","-->"]},{"cell_type":"code","metadata":{"id":"6NCtA_5xlye_","executionInfo":{"status":"ok","timestamp":1605110620449,"user_tz":-120,"elapsed":7841,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO: Implement the logistic function\n","# x can be a number or a numpy array\n","def sigma(x, k=1):\n","    return 1/(1+np.exp(-k*x))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"mMRTJCTGlyfE","executionInfo":{"status":"ok","timestamp":1605110620457,"user_tz":-120,"elapsed":7826,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"9683e168-b0fc-44b2-adc9-78d25bbcd520","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"sigma\")"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"cEccRMSrlyfN"},"source":["To get a sense of the logistic function, we graph it for several values of $k$."]},{"cell_type":"code","metadata":{"id":"KKlCBBQtlyfP","executionInfo":{"status":"ok","timestamp":1605110620976,"user_tz":-120,"elapsed":8279,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"04ca316c-cb42-43aa-f07f-2f0e8871ca83","colab":{"base_uri":"https://localhost:8080/","height":281}},"source":["def sigma_plot():\n","    x = np.linspace(-2, 2, 100)\n","    fig, ax = plt.subplots()\n","    for k in [0, 1, 2, 10]:\n","        ax.plot(x, sigma(x, k), label = f\"k = {k}\")\n","    plt.title(\"Logistic functions\")\n","    plt.legend()\n","    \n","sigma_plot()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"hy3OKETLlyfV"},"source":["<!-- BEGIN QUESTION -->\n","\n","**Question:** What does the $k$ parameter do to the logistic function?\n","<!--\n","BEGIN QUESTION\n","manual: true\n","name: open_response_k\n","-->"]},{"cell_type":"markdown","metadata":{"id":"zsg68VVklyfW"},"source":["As we can see from the plot, from a technical (mathematical/geometrical) point of view, it controlls the slope (int terms of absolute value) of the function, i.e the bigger the k, the bigger the slope and the earlier it becomes almost linear near 0 and 1. \n","In more meaningfull observations as it can be concluded from the technical observation, k controlls the dicision margins of the clasifier, i.e enlarging k makes more examples to be outliers, i.e enlarging their probability to be classified to the corresponding class ('enlarging' - for the opposite direction of the function towards 0, we can say enlarging about the complementary probability 1-epsilon, for the other class).  "]},{"cell_type":"markdown","metadata":{"id":"qbbYX8dalyfY"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","The logistic function, when applied to the weighted average above is greater than 0.5."]},{"cell_type":"code","metadata":{"id":"eevqNOe4lyfZ","executionInfo":{"status":"ok","timestamp":1605110620978,"user_tz":-120,"elapsed":8252,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"147194d6-f2a6-4185-ca42-cf825b8e3ee6","colab":{"base_uri":"https://localhost:8080/"}},"source":["sigma(wtd_sum)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.710949502625004"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"4FilGdQSlyfe"},"source":["In the _Federalist Papers_ classification problem, there are only two classes, so we can use this single value to determine the classification. For an input feature vector $\\vect{x}$ and weight vector $\\vect{w}$, we'll take the model to predict the probability of the author being Hamilton (say), as\n","\n","$$\\Prob(\\mathrm{Hamilton} \\given \\mathbf{x}) = \\sigma(\\mathbf{w} \\cdot \\mathbf{x})$$\n","\n","Therefore, \n","\n","$$\\Prob(\\mathrm{Madison} \\given \\mathbf{x}) = 1 - \\sigma(\\mathbf{w} \\cdot \\mathbf{x})$$\n","\n","since there are only two classes.\n","\n","> When there are more than two classes, we'd use a generalization of the sigmoid function, called [softmax](https://en.wikipedia.org/wiki/Softmax_function).\n","\n","Define a function `predict_lr` that calculates the probability of **Hamilton** being the author of an example text, given a weight vector and the feature vector for the example text.\n","<!--\n","BEGIN QUESTION\n","name: predict_lr\n","-->"]},{"cell_type":"code","metadata":{"id":"lh2StDEGlyfe","executionInfo":{"status":"ok","timestamp":1605110620979,"user_tz":-120,"elapsed":8238,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO: Calculate the probability of Hamilton being the author\n","def predict_lr(weights, features):\n","    return sigma(np.dot(weights, features))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TigxzXtIlyfj"},"source":["This is the _forward computation_ for the logistic regression model, calculating its output prediction from some inputs. Next we turn to the _backward computation_, calculating the updates to the parameters based on any error in the predicted output, as measured by a loss function."]},{"cell_type":"markdown","metadata":{"id":"CW0a7DU2lyfj"},"source":["## Using a logistic regression model to predict Federalist authorship"]},{"cell_type":"markdown","metadata":{"id":"JNXe85ZRlyfl"},"source":["Consider the following two training examples (examples 0 and 9) from the _Federalist_ training dataset:"]},{"cell_type":"code","metadata":{"id":"-_FiSMX_lyfp","executionInfo":{"status":"ok","timestamp":1605110620981,"user_tz":-120,"elapsed":8233,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"e037bb58-1f31-40b5-83dd-cb54f3e8d198","colab":{"base_uri":"https://localhost:8080/"}},"source":["for example in [0, 9]:\n","    pprint(training[example])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["{'authors': 'Hamilton',\n"," 'counts': [9, 6, 2, 0],\n"," 'number': '1',\n"," 'title': 'General Introduction'}\n","{'authors': 'Madison',\n"," 'counts': [17, 0, 0, 1],\n"," 'number': '14',\n"," 'title': 'Objections to the Proposed Constitution from Extent of Territory '\n","          'Answered'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PawBgK9klyfx"},"source":["As above, a logistic regression model is defined by a vector of weights $\\mathbf{w}$, like these:"]},{"cell_type":"code","metadata":{"id":"0HmqD-P4lyfx","executionInfo":{"status":"ok","timestamp":1605110620984,"user_tz":-120,"elapsed":8213,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"d71bd065-0c2c-4b2f-c612-456fcff35de8","colab":{"base_uri":"https://localhost:8080/"}},"source":["weights"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[-0.1, 0.2, 0.3, -1]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"Xa2lLjWklyf2"},"source":["Calculate the predicted Hamilton probabilities for the two examples (examples 0 and 9) above.\n","<!--\n","BEGIN QUESTION\n","name: prob_hamilton_examples\n","-->"]},{"cell_type":"code","metadata":{"id":"c591Rb4vlyf2","executionInfo":{"status":"ok","timestamp":1605110620986,"user_tz":-120,"elapsed":8195,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO\n","prob_hamilton_example0 = predict_lr(weights, training[0]['counts'])\n","prob_hamilton_example9 = predict_lr(weights, training[9]['counts'])"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"kFxRac4klyf6","executionInfo":{"status":"ok","timestamp":1605110620988,"user_tz":-120,"elapsed":8180,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"778dd667-2a57-463d-9463-d7f27447bc93","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"prob_hamilton_examples\")"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"GS-CtK6Nlyf-","executionInfo":{"status":"ok","timestamp":1605110620989,"user_tz":-120,"elapsed":8163,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"99030229-76b6-464c-af72-c35ec59cd6ce","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(f\"example 0 prob of Hamilton: {prob_hamilton_example0:.3f}\\n\"\n","      f\"example 9 prob of Hamilton: {prob_hamilton_example9:.3f}\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["example 0 prob of Hamilton: 0.711\n","example 9 prob of Hamilton: 0.063\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"6baITo_0lygB"},"source":["<!-- BEGIN QUESTION -->\n","\n","**Question:** What does this model predict about the two training examples? Is it correct?\n","<!--\n","BEGIN QUESTION\n","name: open_response_original_model_prediction\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"JN7gzj3rlygC"},"source":["It precits that the probability of the 0-th example to be classified as Hamilton is 0.711, and the probability of the 9-th example to be classified as Hamilton is 0.063, i.e very poor, thus the complementary probability is 1-0.063, is the probability to be classified as 'Madison'. It is correct in both cases."]},{"cell_type":"markdown","metadata":{"id":"og1PZgQ2lygD"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","## Training a logistic regression model\n","\n","Of course, this is just one of an infinite number of models (weight vectors), since we could have set the weights in all kinds of ways. How should we come up with a _good_ model, i.e., a good setting of the weights? Ideally, we'd try to find a set of weights that predicts all of the training data well. This is the problem of _training_ a logistic regression model. Let's try another set of weights:"]},{"cell_type":"code","metadata":{"id":"kQiXsR7ulygE","executionInfo":{"status":"ok","timestamp":1605110620992,"user_tz":-120,"elapsed":8148,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["weights_new = [0.1, 0.2, 0.3, -5]"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"cs0ifYpDlygL"},"source":["Calculate the probabilities generated by the model for these weights.\n","<!--\n","BEGIN QUESTION\n","name: prob_hamilton_examples_new\n","-->"]},{"cell_type":"code","metadata":{"id":"snV_vXUUlygL","executionInfo":{"status":"ok","timestamp":1605110620994,"user_tz":-120,"elapsed":8137,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO\n","prob_hamilton_example0_new = predict_lr(weights_new, training[0]['counts'])\n","prob_hamilton_example9_new = predict_lr(weights_new, training[9]['counts'])"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"TY3nX1QClygQ","executionInfo":{"status":"ok","timestamp":1605110620996,"user_tz":-120,"elapsed":8122,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"9f1eca84-1734-4047-f4fd-22fbbba50ddb","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"prob_hamilton_examples_new\")"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"hmt-SQ7wlygU","executionInfo":{"status":"ok","timestamp":1605110620998,"user_tz":-120,"elapsed":8101,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"63953118-6383-4d74-cec7-ad9655c304a8","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(f\"example 0 prob: {prob_hamilton_example0_new:.3f}\\n\" \n","      f\"example 9 prob: {prob_hamilton_example9_new:.3f}\")"],"execution_count":23,"outputs":[{"output_type":"stream","text":["example 0 prob: 0.937\n","example 9 prob: 0.036\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"xgo7tiATlygX"},"source":["<!-- BEGIN QUESTION -->\n","\n","**Question:**  Is this a better model, a worse model, or neither, at least as far as the two sample examples are concerned? \n","<!--\n","BEGIN QUESTION\n","name: open_response_new_model_prediction\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"O5eD5lfvlygX"},"source":["This model is better, because the predictions is more accurate (93.7% > 71.1% && 96.4% > 93.7%)."]},{"cell_type":"markdown","metadata":{"id":"fkL7XdSslygY"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","An ideal model would give a probability of 1 to the Hamilton examples and a 0 to the Madison examples.\n","For the two sample examples, you'll have noticed that the new weights generate not 1 and 0, respectively, but numbers quite a bit closer to 1 and 0.\n","\n","We could continue trying different weight values to try to improve the performance of the model on these training examples (and others) by trial and error, but a more systematic method is needed. We define a _loss function_, which specifies how bad a model is, and try to minimize the loss function by _stochastic gradient descent_.\n","\n","We'll do a few steps of the process here by hand. It's sufficiently tedious that it's far better to deploy computers on the task, which we'll do in the next lab.\n","\n","## Cross-entropy loss function\n","\n","We'll use the cross-entropy loss function. For an example $i$, we'll use $\\mathbf{x}^{(i)}$ for the feature vector, and $y^{(i)}$ for the actual (gold) label (1 or 0, 1 for Hamilton and 0 for Madison). The predicted probability of the label being 1 will be as per the logistic regression model $\\sigma(\\mathbf{w} \\cdot \\mathbf{x}^{(i)})$, which we will call $\\hat{y}^{(i)}$.\n","\n","The cross-entropy loss for example $i$ as per a model $\\mathbf{w}$ is\n","$$L_{CE}(\\mathbf{w}) = -(y^{(i)} \\log \\hat{y}^{(i)} + (1-y^{(i)}) \\log (1-\\hat{y}^{(i)}))$$\n","\n"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"gbJnvwVolygZ"},"source":["<!-- BEGIN QUESTION -->\n","\n","**Question:** What is the minimum possible value of the cross-entropy loss above? When is that achieved?\n","<!--\n","BEGIN QUESTION\n","name: open_response_ce_loss\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"LPsKJDphlygZ"},"source":["The minimal possible value is 0.\n"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"-xwwIPXxlyga"},"source":["<!-- END QUESTION -->\n","\n","Define a function to compute the cross-entropy loss for a particular model (weight vector), example (feature vector), and gold label:\n","<!--\n","BEGIN QUESTION\n","name: loss\n","-->"]},{"cell_type":"code","metadata":{"id":"p5yUusnblygb","executionInfo":{"status":"ok","timestamp":1605110621004,"user_tz":-120,"elapsed":8093,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO: define the cross-entropy loss function according to the equation above. The output should be a scalar loss.\n","def loss(weights, features, correct):\n","    \"\"\"Returns the cross-entropy loss for a weight vector, a feature\n","       vector and a gold label `correct`.\"\"\"\n","    y_hat = predict_lr(weights,features)\n","    loss = -(correct*math.log2(y_hat)+(1-correct)*math.log2(1-y_hat))\n","    return loss"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"GOkqFgjjlyge","executionInfo":{"status":"ok","timestamp":1605110621008,"user_tz":-120,"elapsed":8071,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"ca14bdab-833d-4d70-d9e3-0a4b83b4a591","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"loss\")"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"NhKmJAZSlygi"},"source":["Use the `loss` function to determine the cross-entropy loss for example 0 for the original model that we used (`weights`), and for the new model (`weights_new`).\n","<!--\n","BEGIN QUESTION\n","name: loss_example0_old_and_new\n","-->"]},{"cell_type":"code","metadata":{"id":"Dz9ub804lygl","executionInfo":{"status":"ok","timestamp":1605110621013,"user_tz":-120,"elapsed":8062,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO: Calculate loss for training[0] under `weights` and `weights_new`\n","\n","loss_example0_old = loss(weights, training[0]['counts'], training[0]['authors']=='Hamilton')\n","loss_example0_new = loss(weights_new, training[0]['counts'], training[0]['authors']=='Hamilton')"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"qVtZo5ZOlygr","executionInfo":{"status":"ok","timestamp":1605110621016,"user_tz":-120,"elapsed":8036,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"4044ea03-9f0f-4f85-a3a3-53551d0204b9","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"loss_example0_old_and_new\")"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"5IsjNGjtlygw","executionInfo":{"status":"ok","timestamp":1605110621688,"user_tz":-120,"elapsed":8675,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"02364f3c-85c5-4407-e026-36fddb4ad2d1","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(f\"Old model loss: {loss_example0_old:.3f}\\n\"\n","      f\"New model loss: {loss_example0_new:.3f}\")"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Old model loss: 0.492\n","New model loss: 0.094\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"B6oMG6Ealyg1"},"source":["<!-- BEGIN QUESTION -->\n","\n","**Question:** Which of the models is better (at least on this example)?\n","<!--\n","BEGIN QUESTION\n","name: open_response_loss_on_example\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"wDzEGoiVlyg2"},"source":["the new model is better (as expected by previous accuracy estimations), it's loss is much lesser then the old's model."]},{"cell_type":"markdown","metadata":{"id":"5u5l8lFNlyg2"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","## Gradient of the loss function\n","\n","We want to find the weights that minimize the loss function. We use gradient descent:\n","\n","1. Find the gradient of the loss function, the direction in which it is increasing fastest.\n","2. Take a step in the opposite direction.\n","3. Repeat.\n","\n","For cross-entropy loss, recall that the partial derivative of the loss function with respect to a single weight $w_j$ is\n","\n","$$ \\frac{\\partial L_{CE}(\\mathbf{w})}{\\partial w_j} = (\\hat{y} - y) x_j $$\n","\n","> At the end of this subsection, we give a problem that explores how this gradient is derived, but you can just assume it for the time being.\n","\n","The gradient combines these partial derivatives for all of the weights.\n","\n","$$ \\nabla L_{CE}(\\mathbf{w}) = \\left[ \\begin{array}{c}\n","    \\frac{\\partial L_{CE}(\\mathbf{w})}{\\partial w_1}\\\\\n","    \\frac{\\partial L_{CE}(\\mathbf{w})}{\\partial w_2}\\\\\n","    \\vdots \\\\\n","    \\frac{\\partial L_{CE}(\\mathbf{w})}{\\partial w_m}\n","    \\end{array} \\right] $$\n","\n","Let's work out an example, using example 0. The counts for example 0 are"]},{"cell_type":"code","metadata":{"id":"431-7fGalyg3","executionInfo":{"status":"ok","timestamp":1605110621718,"user_tz":-120,"elapsed":8690,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"691f96fc-3482-4fd1-ead5-ce873d2211cd","colab":{"base_uri":"https://localhost:8080/"}},"source":["training[0]['counts']"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[9, 6, 2, 0]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"bPDKbZJ3lyg8"},"source":["and the original weights, recall, were"]},{"cell_type":"code","metadata":{"id":"xH0v5nUslyg9","executionInfo":{"status":"ok","timestamp":1605110621752,"user_tz":-120,"elapsed":8691,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"197a8cbd-bcad-4eb8-89d1-f50fdbf1f205","colab":{"base_uri":"https://localhost:8080/"}},"source":["weights"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[-0.1, 0.2, 0.3, -1]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"lgNWKUBUlyhC"},"source":["What is the gradient vector for these `weights` and training example `training[0]`?\n","<!--\n","BEGIN QUESTION\n","name: grad_vector\n","-->"]},{"cell_type":"code","metadata":{"id":"5rnGGHxKlyhD","executionInfo":{"status":"ok","timestamp":1605110621755,"user_tz":-120,"elapsed":8679,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"3d7d3f0e-2079-4eed-d7dd-bc6e97dbcbfe","colab":{"base_uri":"https://localhost:8080/"}},"source":["y_hat = predict_lr(weights, training[0]['counts'])\n","grad_vector = np.dot((y_hat-(training[0]['authors']=='Hamilton')), training[0]['counts'])\n","grad_vector"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-2.60145448, -1.73430298, -0.57810099,  0.        ])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"tFV7HqmolyhJ","executionInfo":{"status":"ok","timestamp":1605110621757,"user_tz":-120,"elapsed":8652,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"d8b94723-6e8b-42cc-cd96-596e88463f91","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"grad_vector\")"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"8vutYK5-lyhO"},"source":["## Adjusting weights against the gradient\n","\n","Step 2 is to adjust the weights in the _opposite_ direction of the gradient.\n","In this case, we compute the new weight vector $w'$ by adding to the weight vector a fraction of the negative gradient:\n","\n","$$ \\mathbf{w}' = \\mathbf{w} - \\eta \\nabla L_{CE}(\\mathbf{w}) $$\n","\n","Here, $\\eta$ is the _learning rate_. The larger $\\eta$ is, the more we move in each step, but if $\\eta$ is too large we risk overshooting. We'll use a learning rate of 0.1 for now. (Setting good learning rates is one aspect of the black arts of machine learning.)"]},{"cell_type":"code","metadata":{"id":"U_7p5zlZlyhO","executionInfo":{"status":"ok","timestamp":1605110621759,"user_tz":-120,"elapsed":8633,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["learning_rate = 0.1"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"SiWzVq63lyhT"},"source":["Calculate the new weight vector using `learning_rate` and `grad_vector`.\n","<!--\n","BEGIN QUESTION\n","name: weights_updated\n","-->"]},{"cell_type":"code","metadata":{"id":"AlnOMkEmlyhW","executionInfo":{"status":"ok","timestamp":1605110621766,"user_tz":-120,"elapsed":8630,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["weights_updated = weights-learning_rate*grad_vector"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"JEMtXKfClyhd","executionInfo":{"status":"ok","timestamp":1605110621773,"user_tz":-120,"elapsed":8615,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"5a258351-5712-4839-97a0-319ec77841aa","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"weights_updated\")"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"tcfnjG4Jlyhh","executionInfo":{"status":"ok","timestamp":1605110621778,"user_tz":-120,"elapsed":8601,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"493d396d-29b2-4e58-c3dc-c0d4e936f3ee","colab":{"base_uri":"https://localhost:8080/"}},"source":["pprint(weights_updated)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["array([ 0.16014545,  0.3734303 ,  0.3578101 , -1.        ])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iG7FOXXwlyho"},"source":["How do these weights perform on the training example we've been using? Let's see."]},{"cell_type":"code","metadata":{"id":"-Fi1wcdplyhp","executionInfo":{"status":"ok","timestamp":1605110621791,"user_tz":-120,"elapsed":8597,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["loss_example0_updated = loss(weights_updated, training[0]['counts'], training[0]['authors']=='Hamilton')"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"-IZ5yph0lyhw","executionInfo":{"status":"ok","timestamp":1605110621793,"user_tz":-120,"elapsed":8583,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"4b849acd-a2bf-43ef-d6d8-3190b9d55ca0","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(f\"Old model loss: {loss_example0_old:.3f}\\n\"\n","      f\"New model loss: {loss_example0_new:.3f}\\n\"\n","      f\"Updated model loss: {loss_example0_updated:.3f}\")"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Old model loss: 0.492\n","New model loss: 0.094\n","Updated model loss: 0.018\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"V-hNz71plyh1"},"source":["If you did this all right, the loss for the updated model, which was generated by taking a single step opposite the gradient from the old model is not only better than the old model, but better than the new model we used above as well. \n","\n","What about the loss on the other example we've been using (example 9)? Calculate the loss for example 9 with the old model (`weights`), the new model (`weights_new`), and the updated model (`weights_updated`):\n","<!--\n","BEGIN QUESTION\n","name: weights_updated_9\n","-->"]},{"cell_type":"code","metadata":{"id":"Rsxj51Dmlyh2","executionInfo":{"status":"ok","timestamp":1605110621795,"user_tz":-120,"elapsed":8572,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}}},"source":["#TODO\n","loss_example9_old = loss(weights, training[9]['counts'], training[9]['authors']=='Hamilton')\n","loss_example9_new = loss(weights_new, training[9]['counts'], training[9]['authors']=='Hamilton')\n","loss_example9_updated = loss(weights_updated, training[9]['counts'], training[9]['authors']=='Hamilton')"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"uook5ovLlyh5","executionInfo":{"status":"ok","timestamp":1605110621796,"user_tz":-120,"elapsed":8559,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"b7741138-b131-4839-edb8-d6bc8e860919","colab":{"base_uri":"https://localhost:8080/","height":46}},"source":["grader.check(\"weights_updated_9\")"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"gY7P7OwQlyh-","executionInfo":{"status":"ok","timestamp":1605110621798,"user_tz":-120,"elapsed":8533,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"11d027e3-ae7d-400a-8ee8-8daf97a32ff3","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(f\"Old model loss: {loss_example9_old:.3f}\\n\"\n","      f\"New model loss: {loss_example9_new:.3f}\\n\"\n","      f\"Updated model loss: {loss_example9_updated:.3f}\")"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Old model loss: 0.094\n","New model loss: 0.052\n","Updated model loss: 2.722\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"5vUxgN5tlyiE"},"source":["<!-- BEGIN QUESTION -->\n","\n","**Question:** Did the update to the model improve its performance on example 9 or make it worse? Why?\n","\n","<!--\n","BEGIN QUESTION\n","name: open_response_updated_9\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"GoXL8eJVlyiH"},"source":["It made it worse because the gradient that minimize one concrete example  of the dataset, in our case example 0 for which we used the loss optimization step, not necessarily and even probably not minimize the loss for another examples (it could happen only if all the examples are very similiar). To achieve this we should use gradient step methods which take a look on a few examples, as mini-batch gradient descent algorithm. It is guaranteed that for all seen examples, for a small enough step and if we are not ocassionaly allready in the optimum, the the loss optimization step will improve the loss for each just seen example. \n"]},{"cell_type":"markdown","metadata":{"id":"OeLmgsPKlyiH"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","## Repeating the process\n","\n","Step 3 is to repeat the process for this and other training examples. We could recalculate the gradient and take another step to improve further, and take steps to improve the other training examples, and so on and so forth, eventually converging on a model that works well over the entire training set. But doing so manually in this way is too tedious. We need to be able to do these kinds of computations at scale. Fortunately, in the next lab we'll be turning to packages that allow specifying these larger-scale computations."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"mGiG68FqlyiI"},"source":["<!-- BEGIN QUESTION -->\n","\n","## Optional Questions\n","The following questions are **optional**, you don't have to submit them.\n","\n","### Optional Question #1 ###\n","In the figure of the logistic function, the logistic function looks to be radially symmetric. In particular, it appears that $\\sigma(x) = 1 - \\sigma(-x)$. (If so, we can use a simple thresholding for classificiation purposes, $\\sigma(x) > 0.5$ to capture $x > 0$.)\n","\n","Prove the identity $\\sigma(x) = 1 - \\sigma(-x)$.\n","\n","<!--\n","BEGIN QUESTION\n","manual: true\n","name: open_response_sigma_identity\n","-->"]},{"cell_type":"markdown","metadata":{"id":"60m0lve1lyiL"},"source":["![1.PNG](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"AhJM1UEglyiM"},"source":["<!-- END QUESTION -->\n","\n","<!-- BEGIN QUESTION -->\n","\n","## Optional Question #2 - Deriving the gradient of the cross-entropy loss\n","\n","\n","Jurafsky and Martin provide a derivation for the cross-entropy loss in their section 5.8. There, they note that the derivation relies on the salutary fact that the derivative of the sigmoid has an especially simple form:\n","\n","$$ \\frac{d \\sigma(z)}{dz} = \\sigma(z) \\cdot (1 - \\sigma(z)) $$\n","\n","**Question:** Prove this identity.\n","\n","> **Hint:** You may find some of the following standard formulas for the derivative of various functions – reviewed from your calculus course – useful. (In these schematic identities, $u$ and $v$ are metavariables over functions of $z$, and $a$ and $n$ are metavariables over constants.)\n","\n","\n","\\begin{align*}\n","\\frac{d}{dz} a &= 0 \\\\\n","\\frac{d}{dz} (u + v) &= \\frac{du}{dz} + \\frac{dv}{dz} \\\\\n","\\frac{d}{dz} (u\\,v) &= v\\frac{du}{dz} + u\\frac{dv}{dz} \\\\\n","\\frac{d}{dz} \\left[\\frac{1}{u}\\right] &= - \\frac{1}{u^2} \\frac{du}{dz} \\\\\n","\\frac{d}{dz} u^n &= n u^{n-1} \\frac{du}{dz} \\\\\n","\\frac{d}{dz} e^u &= e^u \\frac{du}{dz} \\\\\n","\\frac{d}{dz} \\log_a u &= (\\log_a e) \\frac{1}{u} \\frac{du}{dz} \n","\\end{align*}\n","\n","\n","<!--\n","BEGIN QUESTION\n","manual: true\n","name: open_response_sigmoid_gradient\n","-->"]},{"cell_type":"markdown","metadata":{"id":"5a1406U2lyiN"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"VzmLDXPOlyiO"},"source":["<!-- END QUESTION -->\n","\n","<!-- BEGIN QUESTION -->\n","\n","## Lab debrief – for consensus submission only\n","\n","**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n","\n","* Was the lab too long or too short?\n","* Were the readings appropriate for the lab? \n","* Was it clear (at least after you completed the lab) what the points of the exercises were? \n","* Are there additions or changes you think would make the lab better?\n","\n","<!--\n","BEGIN QUESTION\n","name: open_response_debrief\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"PBmzDaG8lyiQ"},"source":["_Type your answer here, replacing this text._"]},{"cell_type":"markdown","metadata":{"id":"bNvdiCOalyiR"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","# End of lab 1-4"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"TDcaW47XlyiT"},"source":["---\n","\n","To double-check your work, the cell below will rerun all of the autograder tests."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"Ju2LNrdHlyiU","executionInfo":{"status":"ok","timestamp":1605110621800,"user_tz":-120,"elapsed":8529,"user":{"displayName":"Ilya Kotlov","photoUrl":"","userId":"00819922945080322606"}},"outputId":"9d156222-c9d3-4282-c10e-a00317a342a2","colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["grader.check_all()"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/html":["<p><strong>grad_vector:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>loss:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>loss_example0_old_and_new:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>prob_hamilton_examples:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>prob_hamilton_examples_new:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>sigma:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>weights_updated:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>weights_updated_9:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>wtd_sum:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n"],"text/plain":["grad_vector:\n","\n","    All tests passed!\n","    \n","\n","loss:\n","\n","    All tests passed!\n","    \n","\n","loss_example0_old_and_new:\n","\n","    All tests passed!\n","    \n","\n","prob_hamilton_examples:\n","\n","    All tests passed!\n","    \n","\n","prob_hamilton_examples_new:\n","\n","    All tests passed!\n","    \n","\n","sigma:\n","\n","    All tests passed!\n","    \n","\n","weights_updated:\n","\n","    All tests passed!\n","    \n","\n","weights_updated_9:\n","\n","    All tests passed!\n","    \n","\n","wtd_sum:\n","\n","    All tests passed!\n","    \n"]},"metadata":{"tags":[]},"execution_count":42}]}]}