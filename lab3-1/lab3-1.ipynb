{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false, "jupyter": {"outputs_hidden": true, "source_hidden": true}}, "outputs": [], "source": ["# Please do not change this cell because some hidden tests might depend on it.\n", "import os\n", "\n", "# Otter grader does not handle ! commands well, so we define and use our\n", "# own function to execute shell commands.\n", "def shell(commands, warn=True):\n", "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n", "     \n", "       Prints the result to stdout and returns the exit status. \n", "       Provides a printed warning on non-zero exit status unless `warn` \n", "       flag is unset.\n", "    \"\"\"\n", "    file = os.popen(commands)\n", "    print (file.read().rstrip('\\n'))\n", "    exit_status = file.close()\n", "    if warn and exit_status != None:\n", "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n", "    return exit_status\n", "\n", "shell(\"\"\"\n", "ls requirements.txt >/dev/null 2>&1\n", "if [ ! $? = 0 ]; then\n", " rm -rf .tmp\n", " git clone https://github.com/cs236299-2020/lab3-1.git .tmp\n", " mv .tmp/tests ./\n", " mv .tmp/requirements.txt ./\n", " rm -rf .tmp\n", "fi\n", "pip install -q -r requirements.txt\n", "\"\"\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["# Initialize Otter\n", "import otter\n", "grader = otter.Notebook()"]}, {"cell_type": "raw", "metadata": {}, "source": ["%%latex\n", "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\newcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\newcommand{\\softmax}{\\operatorname{softmax}}\n", "\\newcommand{\\Prob}{\\Pr}\n", "\\newcommand{\\given}{\\,|\\,}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$$\n", "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n", "\\renewcommand{\\Prob}{\\Pr}\n", "\\renewcommand{\\given}{\\,|\\,}\n", "$$"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "rItk09M3jy74"}, "source": ["# Lab 3-1 \u2013 Context-free grammars introduced"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "o003ofo5rMpT"}, "source": ["## Preparation \u2013 Loading packages"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "editable": false, "id": "i0VizT9Mrbl8"}, "outputs": [], "source": ["import functools\n", "import math\n", "import nltk"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "b3hDWXsHzRUU"}, "source": ["## Writing CFGs"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "AXgnux98rrbb"}, "source": ["Recall that a context free grammar (CFG) is a set of rules of the form $A \\rightarrow \\beta$, where $A$ is a nonterminal symbol and $\\beta$ is a sequence of terminal and nonterminal symbols. The set of nonterminals is $N$ and the set of terminals is $\\Sigma$. One of the nonterminals is a special start symbol, conventionally denoted $S$. \n", "\n", "We will use the [Natural Language Tool Kit (NLTK)](http://nltk.org) to define, represent, and store context-free grammars and syntactic parse trees in data structures. The toolkit provides for constructing a grammar from a textual description, such as this example:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "1ATwDTO_wE8i"}, "outputs": [], "source": ["simple_grammar1 = nltk.CFG.fromstring(\"\"\"\n", "    S -> NP VP\n", "    NP -> 'dogs'\n", "    NP -> 'cats'\n", "    NP -> 'husky' 'dogs'\n", "    VP -> V\n", "    VP -> V NP\n", "    V -> 'bark'\n", "    V -> 'jump'\n", "    V -> 'chase'\n", "\"\"\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "AXgnux98rrbb"}, "source": ["Some things to notice about the NLTK encoding of grammars:\n", "\n", "* Nonterminals are those symbols that appear on the left-hand side of a rule. \n", "* Terminals are any other Python object, but typically (as here) a string. (Notice how to write multi-word expressions on the right-hand side.)\n", "* The start symbol is the left-hand side of the first production of the grammar, and typically denoted as \"S\"."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "N3fsdH_cF89C"}, "source": ["We can print the grammar to observe it:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "tYKY8dGiGBMk"}, "outputs": [], "source": ["print(simple_grammar1)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "kv0lwa1VwD7q"}, "source": ["Some sentences that are *generated* by this grammar include \"dogs bark\", \"cats jump\", and \"dogs chase cats\". \n", "\n", "> This grammar also generates sentences that are ungrammatical in English, such as \"dogs bark cats\", as it makes no distinction between intransitive verbs (like \"bark\") and transitive verbs (like \"chase\"). For now, we'll ignore this issue.\n", "\n", "The [`nltk.CFG.fromstring`](http://www.nltk.org/api/nltk.html#nltk.CFG.fromstring) function also accepts grammars in a shorthand notation using the \"or\" operator `|` to combine multiple productions with the same left-hand side."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "DZe9Rak2x-V-"}, "outputs": [], "source": ["simple_grammar2 = nltk.CFG.fromstring(\"\"\"\n", "    S -> NP VP\n", "    NP -> 'dogs' | 'cats' | 'husky' 'dogs'\n", "    VP -> V | V NP\n", "    V -> 'bark' | 'jump' | 'chase'\n", "\"\"\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "REHNTp72GME4"}, "source": ["You can verify that the grammar is identical by printing it."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 170}, "colab_type": "code", "id": "wzZb-iAjGQl7", "outputId": "d70d74d8-dbad-4ae0-f1dd-40534abeffd3"}, "outputs": [], "source": ["print(simple_grammar2)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "4HSkx1iuzprr"}, "source": ["## Arithmetic expressions\n", "**What is four plus one divided by two?** As you can see in the screenshot at right, Alexa has a specific answer to this question. \n", "<img src=\"https://github.com/nlp-course/data/raw/master/img/alexa_arithmetic.jpg\" width=150 align=right />\n", "\n", "In this lab, you will learn how to implement the first part of answering such \"arithmetic in English\" questions. In particular, you will write CFGs for a subset of the language of arithmetic expressions. You can assume that numbers are integers between zero and twenty and that the allowed operations are addition, subtraction, multiplication, and division. First, construct a CFG that generates the following expressions and similar ones. (For now, don't worry about issues of ambiguity.) \n", "\n", "1. twenty plus two\n", "1. fifteen minus five\n", "1. four divided by two plus one\n", "1. two plus nine times five minus three\n", "1. sixteen plus two minus ten times one\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: arithmetic_grammar\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "WIwYmzTKzFl5"}, "outputs": [], "source": ["#TODO - construct a CFG for simple arithmetic expressions \n", "all_numbers = \"'zero' | 'one' | 'two' | 'three' | 'four' | 'five' \" \\\n", "            + \"| 'six' | 'seven' | 'eight' | 'nine' | 'ten' | 'eleven' \" \\\n", "            + \"| 'twelve' | 'thirteen' | 'fourteen' | 'fifteen' \" \\\n", "            + \"| 'sixteen' | 'seventeen' | 'eighteen' | 'nineteen' | 'twenty'\"\n", "arithmetic_grammar = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"arithmetic_grammar\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "xMdFOXrX4kD_"}, "source": ["## Trees and grammars\n", "\n", "Create a parse tree each for sentences 2 and 3 according to your grammar. \n", "\n", "**Draw** the parse trees on a piece of paper or any drawing application. \n", "You'll use these drawings in this notebook shortly.\n", "\n", "Go ahead; we'll wait...."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "GSBHwst5GdpU"}, "source": ["You're back. Good.\n", "\n", "Drawing parse trees is a helpful visualization, but we need a machine-readable format for trees. One such format is a bracket notation.  For example, a parse tree for \"dogs bark\" can be made as follows, using the [`nltk.Tree.fromstring`](http://www.nltk.org/api/nltk.html#nltk.tree.Tree.fromstring) function: "]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "ah4Kvmkw-nJ2"}, "outputs": [], "source": ["tree = nltk.Tree.fromstring(\"(S (NP dogs) (VP (V bark)))\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "RUXnkjvUXjRX"}, "source": ["We can visualize the tree using the `pretty_print` method:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "VYYvfLoEXocy"}, "outputs": [], "source": ["tree.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "5p6Zzc6Bz-PN"}, "source": ["You can get the rules that generated a tree using the `productions` method:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "R_FSvU_Rz_pv"}, "outputs": [], "source": ["tree.productions()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "58zWEl1-G1aF"}, "source": ["Convert the parse trees you drew for sentences 2 and 3 into NLTK format by converting them from a string using bracket notation, as done above for `tree`.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: parse_trees\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "466Vl9u-7Fvv"}, "outputs": [], "source": ["#TODO\n", "# \"fifteen minus five\"\n", "tree2 = ...\n", "# \"four divided by two plus one\"\n", "tree3 = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"parse_trees\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "fm_6FsGYHH4A"}, "source": ["It's useful to draw the trees to make it easier to visually inspect them. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 323}, "colab_type": "code", "id": "7iJ4NXy-8CAH", "outputId": "115c03a3-5c68-4de7-964a-91f19cc35788"}, "outputs": [], "source": ["tree2.pretty_print()\n", "tree3.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "rlFVC1uNyYak"}, "source": ["The following function validates that a tree only contains production rules that are valid according to given grammar. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "jJSUjlFLxWDc"}, "outputs": [], "source": ["def validate(tree, grammar):\n", "    return functools.reduce(lambda accum, production: \n", "                               accum and production in grammar.productions(),\n", "                            tree.productions())"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "m1NqTqFhyrjO"}, "source": ["Using the `validate` function, we can validate that the trees your wrote are valid with respect to your grammar. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "QIbldgGlyyXI"}, "outputs": [], "source": ["print(validate(tree2, arithmetic_grammar))\n", "print(validate(tree3, arithmetic_grammar))"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "t8SW_b_iAYSM"}, "source": ["## Expanding the grammar\n", "The arithmetic expressions we considered so far were rather limited. In practice, there are many ways to express such expressions. Expand your grammar to generate also the following expressions, in addition to the previous ones:\n", "\n", "6. the sum of twenty and two\n", "1. the difference between fifteen and five\n", "1. the quotient of three and five\n", "1. the sum of the quotient of four and two and one \n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: expanded_arithmetic_grammar\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "-UCx8QgBBrmh"}, "outputs": [], "source": ["#TODO\n", "all_numbers = \"'zero' | 'one' | 'two' | 'three' | 'four' | 'five' \" \\\n", "            + \"| 'six' | 'seven' | 'eight' | 'nine' | 'ten' | 'eleven' \" \\\n", "            + \"| 'twelve' | 'thirteen' | 'fourteen' | 'fifteen' \" \\\n", "            + \"| 'sixteen' | 'seventeen' | 'eighteen' | 'nineteen' | 'twenty'\"\n", "expanded_arithmetic_grammar = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"expanded_arithmetic_grammar\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "2ITEYgtIDGpG"}, "source": ["Create parse trees for sentences 6 and 9 according to your grammar. Again, you might find it useful to first draw the trees by hand and then write them in bracket notation using the `nltk.Tree.fromstring` function. \n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: expanded_arithmetic_trees\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 323}, "colab_type": "code", "id": "bRZv2eA6DrFB", "outputId": "6462095d-02b8-433a-dd95-e7140e754a76"}, "outputs": [], "source": ["#TODO\n", "# \"the sum of twenty and two\"\n", "tree6 = ...\n", "# \"the sum of the quotient of four and two and one\" \n", "tree9 = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"expanded_arithmetic_trees\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 323}, "colab_type": "code", "id": "bRZv2eA6DrFB", "outputId": "6462095d-02b8-433a-dd95-e7140e754a76"}, "outputs": [], "source": ["tree6.pretty_print()\n", "tree9.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "PUGQyC3SH8vd"}, "source": ["## Testing the grammar\n", "Now that you have a CFG for arithmetic expressions, it is time to test its capabilities. Can your grammar generate the following new expressions? If not, edit the grammar to make sure it can handle such expressions.\n", "\n", "10. three added to eight\n", "1. the sum of two and nine times the difference between five and three\n", "1. ten\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: further_testing\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "1TaRlKfoJU8a"}, "outputs": [], "source": ["#TODO\n", "expanded_arithmetic_grammar = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"further_testing\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "0CH8zJUNJeey"}, "source": ["## Preview to parsing\n", "Verifying by hand that a sentence can be generated by a grammar is cumbersome and impractical. We would like an automatic procedure for doing that at scale, that is, a *parser*. The `nltk` system can construct a parser given a grammar. In later labs, you'll write your own parsers."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "RXtsVzw1J-JD"}, "outputs": [], "source": ["parser = nltk.parse.BottomUpChartParser(expanded_arithmetic_grammar)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "XA83jnFnKIem"}, "source": ["Using this parser we can get parses for a given sentence."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 391}, "colab_type": "code", "id": "9ocKnMIyKNyv", "outputId": "7996d042-d306-4266-e786-79ddee0dfc45"}, "outputs": [], "source": ["test_sentence = \"the sum of two and nine times the difference between five and three\".split()\n", "for tree in parser.parse(test_sentence):\n", "    tree.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "7d12uabHTO9k"}, "source": ["You may have noticed that some of the arithmetic expressions were *ambiguous*; they had multiple distinct valid parses. In the next few labs, we will deal with the important matter of ambiguity. "]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "2i71ToeARzPk"}, "source": ["## Parser evaluation\n", "To evaluate the quality of a syntactic parser, we need an evaluation metric to compare a predicted _hypothesis_ parse with a gold _reference_ parse. Common evaluation metrics include:\n", "\n", "1. Exact match \u2013 1 if the predicted and reference parses are identical; 0 otherwise\n", "2. Precision $P$ \u2013 the proportion of constituents in the hypothesis that are correct (that is, match the gold parse)\n", "$$P = \\frac{\\cnt{\\text{correct constituents in a hypothesis parse}}}{\\cnt{\\text{constituents in a hypothesis parse}}}$$\n", "1. Recall $R$ \u2013 the proportion of constituents in the gold parse that are predicted (that is, match the hypothesis parse)\n", "$$R = \\frac{\\cnt{\\text{correct constituents in a hypothesis parse}}}{\\cnt{\\text{constituents in a reference parse}}}$$\n", "1. $F_1$ score \u2013 the harmonic mean of precision and recall\n", "$$F_1 = \\frac{2}{1/P+1/R} = \\frac{2PR}{P+R}$$\n", "\n", "We consider a constituent in one tree to match a constituent in another if they share the same nonterminal and cover the same span of terminal symbols. We don't count the terminals by themselves as constituents, so, for instance, the `ref_tree` we define below has five constituents, not eight.\n", "\n", "Consider the following trees, a reference tree `ref_tree` (the \"gold\" or \"ground truth\") and hypothesis tree `hyp_tree` (usually, the \"predicted\" tree that we wish to measure)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 289}, "colab_type": "code", "id": "ODyuiNeTbYsE", "outputId": "d5410bed-36c2-4bec-eea5-f1cead12af99"}, "outputs": [], "source": ["ref_tree = nltk.Tree.fromstring(\"(S (NP dogs) (VP (V chase) (NP cats)))\")\n", "ref_tree.pretty_print()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 289}, "colab_type": "code", "id": "ODyuiNeTbYsE", "outputId": "d5410bed-36c2-4bec-eea5-f1cead12af99"}, "outputs": [], "source": ["hyp_tree = nltk.Tree.fromstring(\"(S (S  (NP dogs) ) (VP (V chase) (NP cats)))\")\n", "hyp_tree.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "wC0v3XabbLoP"}, "source": ["Calculate (by hand) the precision, recall, and $F1$ of the hypothesis tree `hyp_tree` relative to the reference tree `ref_tree`.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: metrics\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "JWEDpll_dzWk"}, "outputs": [], "source": ["#TODO\n", "precision = ...\n", "recall = ...\n", "f1 = ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"metrics\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "nE1iWD7keyn3"}, "source": ["### The precision-recall tradeoff\n", "\n", "Often there is a tradeoff between precision and recall. In the above example, the recall is good, but at the expense of precision.\n", "\n", "Find the minimal tree with a precision of $1$ with regards to the above `ref_tree`. (The tree does **not need to be valid** according to the grammar.) \n", "\n", "What is its recall? \n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: tradeoff\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "Y-B4pKD_haw5"}, "outputs": [], "source": ["#TODO\n", "minimal_high_precision_tree = ...\n", "recall_of_minimal_high_precision_tree = ...\n", "minimal_high_precision_tree.pretty_print()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"tradeoff\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "BhvuUn3pXDnq"}, "source": ["## Chomsky Normal Form\n", "\n", "As you have seen above, there are many ways to write a grammar for a given language. It is often convenient, however, to work with a standard format. A grammar in Chomsky Normal Form (CNF) has rules of only two kinds:\n", "\n", "> Actually, this version of CNF can't express languages that contain the empty string. To allow expression of any context-free language, we can allow a third type of rule $S \\rightarrow \\epsilon$, where $S$ is the start symbol of the grammar and $\\epsilon$ represents the empty string. But for our purposes, we'll stick to the simpler version here.\n", "\n", "1. $A \\rightarrow B \\, C$ \u2013 a rule mapping a nonterminal symbol to exactly two nonterminal symbols\n", "2. $A \\rightarrow a$ \u2013 a rule mapping a nonterminal symbol to exactly one terminal symbol\n", "\n", "A CFG parse tree can be transformed to one generable by a CNF grammar in a variety of ways, typically by introducing special new nonterminals. Here, we use `nltk` to perform the transformation. The result is a binary tree. The binary branching property will turn out to be useful when we turn to implementing parsers."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "1tmu3YEeXG6d"}, "outputs": [], "source": ["tree = nltk.Tree.fromstring(\"(S (NP dogs) (CONJ and) (NP cats) )\")\n", "tree.pretty_print()\n", "tree.chomsky_normal_form()\n", "tree.pretty_print()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "s7GiZVWXXKwv"}, "source": ["Some parsing algorithms require the grammar to be in CNF. Manually convert the arithmetic grammar you wrote in the first part of this lab (`arithmetic_grammar`) to CNF. You may need to introduce \"dummy\" nonterminals to allow that. \n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: cnf_conversion\n", "-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "TK9eJNIIXhCP"}, "outputs": [], "source": ["#TODO\n", "cnf_arithmetic_grammar = nltk.CFG.fromstring( \n", "    ...\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"cnf_conversion\")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "uy2rgnIPXo7Q"}, "source": ["The NLTK grammar method `is_chomsky_normal_form` allows us to verify that the grammar is indeed in CNF:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "wW50aW2wXsBu"}, "outputs": [], "source": ["cnf_arithmetic_grammar.is_chomsky_normal_form()"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "## Lab debrief \u2013 for consensus submission only\n", "\n", "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n", "\n", "* Was the lab too long or too short?\n", "* Were the readings appropriate for the lab? \n", "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n", "* Are there additions or changes you think would make the lab better?\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_debrief\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "# End of lab 3-1"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["---\n", "\n", "To double-check your work, the cell below will rerun all of the autograder tests."]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check_all()"]}], "metadata": {"colab": {"authorship_tag": "ABX9TyNciiuGUJ1469rIOJf9y6N+", "collapsed_sections": [], "include_colab_link": true, "name": "lab6.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}, "title": "236299 Lab 3-1: Context-free grammars introduced"}, "nbformat": 4, "nbformat_minor": 4}